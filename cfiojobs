#!/bin/bash
###########################################################
# Author  : william mei
# Date    : 20181010
# version : cfiojobs0.12.53
# Test platform:
#               kernel     : 3.10.0-514.26.2.el7.x86_64
#               OS release : CentOS 7.3.1611
#               Shell type : GNU Bash-4.2
# description  :
#               send files/command to multy host 
#               parallel fio test on clusters 
# last edit :   20181225
###########################################################

script_version=0.12.86

#ssh_timeout=15
#host_concurrency_max=500

#main_pid="$$"
check_stat=0
tmpfile_dir=$(mktemp -d)

#date_time=$(date "+%Y-%m-%d_%H:%M:%S")
date="$(date +%Y%m%d%H%M)"
g_conf="$0"".grp"
b_conf="$0"".blk"
j_conf="$0"".job"

# import function from lib 
#[[ -f /etc/init.d/functions ]] && . /etc/init.d/functions 
#. $(dirname)/lib/centos_sys/functions 

# init ssh and basic functions 
. $(dirname $0)/lib/usr_profile 
. $(dirname $0)/lib/global_profile 

# basic functions 
. $(dirname $0)/lib/modules/functions 
. $(dirname $0)/lib/centos_enhanced/functions 

function _clean_up(){
    # clean up tmp files
    sleep $[ssh_timeout * 2]  &&  rm -rf $tmpfile_dir &>/dev/null  &
    for i in ${!tmpfile*} ;do
        local trash_file=$(eval echo \$"$i")
        [[ -f $trash_file ]] && rm -f $trash_file &>/dev/null
        [[ -d $trash_file ]] && rm -rf $trash_file &>/dev/null
    done
    [[ $strict_concurrent_controle == "True" ]] && _cleanup_concurrency_env 
}
function _test_abort(){
    [[ -f $outputdir/recover.log ]] && echo "test aborting at $(date)" >>$output_dir/recover.log
    # reply to multiple kill signals
    if grep -q aborting $output_dir/recover.log &>/dev/null ;then
        echo "test stop action is in progress, please wait."
    else
        # if fio test were started
        if [[ $send_fio == "True" ]]  ;then
           # runner=$(whoami)
           # # stop fio test 
           # [[ -z ${blk_group_list// /} ]] || \
           # for blk_group_name in $ $blk_group_list ;do
           #     [[ -z ${host_group_list// /} ]] || \
           #     for host_group_name in $host_group_list ;do
           #         # kill local test process 
           #         kill $(ps aux |grep $runner |grep "'--fio'" |grep $blk_group_name |grep $host_group_name |grep -v grep|awk '{print$2}') &>/dev/null
           #     done
           # done && wait 
           # # bknd ssh process for fio cmd 
           # keywords="fio filename= rbdname="
           # for kwd in $keywords; do
           #     kill $(ps aux |grep $runner |grep ssh |grep $kwd |grep -v grep|awk '{print$2}') &>/dev/null
           # done
            # force kill fio process and harvest all logs, log dir will be auto removed. 
            for host_group_name in $host_group_list ;do
                tolerate="True"
                _group_fio_stop $host_group_name
                _group_fio_log_harvest $host_group_name 
            done && wait 
        fi
    fi
    _clean_up 
    echo "test stoped at $(date)" >>$output_dir/recover.log
    [[ $send_fio == "True" ]] && echo "test \"$output_dir\" stoped now" || echo "tasks all stoped" 
}
function _reload_host_group_config(){
    _segline "reload host group config file with signal 1"
    if _grp_conf_check ;then 
        _host_group_check
        local reload_stat=$?
        if [[ $reload_stat -eq 0 ]] ;then
            _info "reload host group config file seccess"
        else
            _error "reload host group config file failed."
        fi 
        _segline "host group config file reloaded"
    else
        _warn "The current host group config file can not be reloaded by $0 !!"
        _warn "The old grp conf info will be remained, but please check your new host group config file as soon as possible!!"
    fi 
}
trap " _reload_host_group_config " 1
trap "echo -e '\n job stoped with user signals, stop running, please wait ...'; _test_abort; exit $check_stat" 2 3 15

##############################################################################################
# Global ARRAY:
# declare golbal arrays to common data storage
# 1. blk group
    # all blk group info will be stored in this union array, keywords $blk_group_name.
    declare -A BLK_DEV_ARRAY 
# 2. job group
    #store all job bs/pattern/args in those union array, common keywords $job_group_name
    declare -A VALID_JOB_INFO_ARRAY \
                  JOB_RUNTIME_ARRAY \
                JOB_DATA_SIZE_ARRAY \
                       JOB_BS_ARRAY \
                  JOB_PATTERN_ARRAY \
                     JOB_ARGS_ARRAY 
#   an index array to store all job batchs.
    declare -a      JOB_BATCH_ARRAY \
                    JOB_BATCH_NAME_ARRAY
# a global variable to store all job batchs
#    JOB_BATCH_LIST=""
# 3. host group
    #store all host group info in those union array, common keywords $host_group_name
    declare -A VALID_HOST_GROUP_INFO_ARRAY \
                     HOST_GROUP_USER_ARRAY \
                     HOST_GROUP_PORT_ARRAY \
                     HOST_GROUP_BKND_ARRAY \
                     HOST_GROUP_SH_MODE_ARRAY \
                     HOST_GROUP_IP_LIST_ARRAY 
#
    declare -A       HOST_GROUP_RBD_DEV_ARRAY # host_name 
# a shell array can't contain another array, so set a tmp_delimiter for later access.
#    tmp_delimiter=','
#    OLD_IFS="$IFS"dd
#    tmpfifo=/tmp/tmp."$$"'.fifo'
#
# an output dir list file have all output dir,host group, job group inof stored.
#    echo "" >$0".dirlist"
# temperary history file.
    echo "$(date "+%Y-%m-%d_%H:%M:%S"): $$ $0 $@" >>$0".hst"
    conflict_args="$*"
##############################################################################################
function _unquiet(){
# give inof when not quiet mode.
    if [[ $quiet_mode == "True" ]] ;then
        # mute 
        return 1
    else 
        # echo 
        echo -e "$@"
        return 0
    fi
}
function _tmp_quiet(){
    # $1 on/off  
    [[ $quiet_mode == "True"  ]] && QUIET[global]="True"
    if [[ $1 == "on" ]] ;then
        QUIET[local]="True"
    elif [[ $1 == "off" ]] ;then 
        QUIET[local]="False"
    fi
}
function _local_unquiet(){
    # check local .
    if [[ ${QUIET[local]} == "True" ]] ;then
        # mute 
        return 1
    elif [[ ${QUIET[local]} == "False" ]] ;then 
        # echo
        echo -e "$@"
    #check golbal
    else 
        _unquiet "$@"
    fi
}
# concurrency 
function _host_concurrent_pipe_strict(){
    # host_exec_function must be set before it's called 
    for host_ip in $ip_list ;do 
        {
            _join_concurrent_troop
            eval $host_exec_function $host_ip
            _leave_concurrent_troop 
        } &
    done && wait 
}
function _host_concurrent_pipe(){
    # host_exec_function must be set before it's called 
    [[ $# -gt 0  ]] && exec 0<$1
    while read partial_ip ;do
        #
        for host_ip in $partial_ip ;do
            eval $host_exec_function $host_ip &
        done
        wait
    done<&0;
    exec 0<&-
}
function _run_in_concurrent_pipe(){
    # host_exec_function must be pre-defined 
    # parameters 
    #echo $ip_list
    if [[ $strict_concurrent_controle == "True" ]] ;then 
        _host_concurrent_pipe_strict
    else
        #
        echo $ip_list |xargs -n$host_concurrency_max | _host_concurrent_pipe 
    fi
}
function _update_check_stat(){
    # add new value to file
    # $1 STAT
    # $2 stat_file
    if [[ -n $2 ]] ;then
        if [[ -f $2 ]] ;then 
            #grep -q $1 $2 || echo $1 >>$2
            echo $1 >>$2
        else
            _verbose "stat file is missing. ${FUNCNAME[@]}"
        fi 
    else
        _verbose "stat file is needed, now it's empty. ${FUNCNAME[@]}"
        # _error_interrupt 
    fi
}
function _error_interrupt(){
#  intterupt script when not debug or no tolerate mode.
#  test with the rest, and wait 3s if need break.
    if [[ $pdebug == "True" ]] ;then
        echo "contunue with test arg \"-d\""
        #wait time out then continue
        _timeout "5"
    elif [[ $tolerate == "True" ]] ;then
        _red "  skip failure and try to continue ..."
    else
    # 2. exit none pdebug
        echo "$(_red " ERROR"): $(date "+%Y-%m-%d_%H:%M:%S"): partially failure occured, script breaks here: $( _yellow "${FUNCNAME[@]:1}")."
        _blue "you can use '-f' or '-d' option to skip the failed part."
        _test_abort && exit 1
    fi
}
function _confirm_check_stat(){
    # $1 stat_file
    local stat_file="$1"
    if [[ -f $stat_file ]] ;then
        local connection_no=$(wc -l <$stat_file)
        local connection_survivors=$(grep ^0$ $stat_file |wc -l)
        if [[ $connection_no -eq 0 ]] ;then
            # empty file
            local check_stat=0
        else
            # check_stat=max_return
            local check_stat=$(sort -nr $stat_file |head -1)
        fi
        echo "$connection_no connections, $connection_survivors alive, check stat: $check_stat"
        # if failed, try to stop
        if [[ $connection_survivors -lt 1 ]] ;then
            echo -e "\e[1;31m All $connection_no Connection Failed or No Host Alive! \e[0m"
            #_timeout 15
            _error_interrupt
        elif [[ $check_stat -ge 1 ]] ;then
            echo "Partial Connection Failure occured." 
            #_timeout 15
            _error_interrupt
        fi
    fi
}
function _verbose(){
# print info help testing script
# return 1 when pdebug is True
if [[ $pdebug == "True" ]] && [[ -n $1 ]] ;then
    echo "function :${FUNCNAME[@]:1}"
    _blue "info:
##############################################"
    infotype=$1
#---------------------------------------------
    if [[ $infotype == "funcinfo" ]]
then
    :
#---------------------------------------------
    elif [[ $infotype == "roundinfo" ]]
then
_blue "\
 NO. JOB ROUND: $job_batch_index 
 arguments set:\n\t $job_batch \n"
#---------------------------------------------
    elif [[ $infotype == "hostinfo" ]]
then
_blue "\
blk group  name: $blk_group_name
job batch round: $job_batch_index
host group name: $current_host_group 
current    host: $host_ip " 
#---------------------------------------------
    elif [[ $infotype == "jobinfo" ]] 
then
_blue "\
send_fio :$send_fio
blk group:$blk_group_name
job group:$job_group_name
hostgroup:$current_host_group
host ip  :$host_ip
outputdir:$output_dir
log_dir  :$log_dir
log_name :$log_name
test_mode:$test_mode
BLK  name:$BLK
##############################################
$fio_cmd \
-filename=$BLK \
$size_info $rand_arg
-name=$tag-$log_name &>$log_dir/$log_name
"
#---------------------------------------------
    elif [[ $infotype == "bkndinfo" ]] 
then
_blue "\
jobgroup : $job_group_name
runtime  : ${JOB_RUNTIME_ARRAY[$job_group_name]}
tcmu log : $tcmu_logfile
ceph log : $ceph_logfile
"
#---------------------------------------------
    elif [[ $infotype == "bknddetail" ]] 
then
_blue "\
bknd: $bknd_user
ip  : $bknd_ip
port: $bknd_port
"
#---------------------------------------------
    elif [[ $infotype == "groupinfo" ]] 
then
_blue "\
blk group: $blk_group_name
job round: $job_batch_index
job group: $job_group_name
job  name: $job_name
fio   cmd: $fio_cmd
host_user: $host_user
host_port: $host_port
bknd_grps: ${bknd_grps}
bknd_mode: ${bknd_mode}
host list: ${ip_list}
"
#---------------------------------------------
# get from job conf file
    elif [[ $infotype == "expansion" ]] 
then
_blue "\
total Round_No:$total_round, 
inner Round_No:${ground[$job_group_name]}, 
batch   detail:
        fio 
        -bs=$BS 
        -rw=$PATTERN 
        -size=${JOB_DATA_SIZE_ARRAY[$job_group_name]} 
        -runtime=${JOB_RUNTIME_ARRAY[$job_group_name]} 
        ${JOB_ARGS_ARRAY[$job_group_name]} 
"
#---------------------------------------------
    fi
_blue "\
##############################################"
else
    [[ $pdebug == "True" ]] && return 0 || return 1
fi
}
#----------------------------------------|failure info |-----------------------
function _log_output_dir_check_ok(){
    # 2 scenario
    if [[ $send_fio == "True" ]] || [[ -n $harvest_file_group_list  ]] || [[ -n $output_dir ]];then
        _check_output_dir 
        return 0
    else
        return 1
    fi
}
function _record_cmd(){
    # called by _ssh_send only 
    # cmd status : $1
    # cmd content = "$2 ... end"
    if _log_output_dir_check_ok ;then
        local failure_time=$(date "+%Y-%m-%d %H:%M:%S")
        local cmd_stat=$1
        shift
        echo "$failure_time,$host_group_name,$host_ip,cmd_stat:$cmd_stat,${*}" >$output_dir/all_ssh_cmd.log
    fi
}
# store log info to output_dir 
function _record_fail(){
    if _log_output_dir_check_ok ;then
        local failure_time=$(date "+%Y-%m-%d %H:%M:%S")
        local failure_type="${FUNCNAME[1]}" # parent function name or name passed in.
        if [[ ${FUNCNAME[-2]} == "_fio_scale_control" ]] ;then
            # in a fio test 
            local failure_stage=${FUNCNAME[-4]} 
        else
            # the last one is main 
            local failure_stage="${FUNCNAME[-2]}" 
        fi
        [[ -z $job_batch_index ]] && failure_note="not in test" || local failure_note="round $job_batch_index"
        echo "$failure_time,$host_group_name,$host_ip,$failure_stage,$failure_type,$failure_note" >>$output_dir/failure_host.csv  
    fi 
}
function _pingfail(){
    # give unreachable host info
    _red "  host:$host_ip unreachable."
    _record_fail
}
function _sshfail(){
    # give ssh connection failed info 
    _red "  host:$host_ip ssh connection failed."
    _record_fail
}
function _devfail(){
    [[ -n $blk ]] && local dev_name=$blk || local dev_name=$BLK 
    # give device check failed info 
    _red "  host:$host_ip dev:$dev_name not a valid test device."
    _record_fail
}
function _cmdfail(){
    # if ping ok or --no-ping 
    #give command return value check failed info 
    _record_fail
}

##############################################################################################
# config file check
##############################################################################################
function _grp_conf_check(){
    if [ -f $g_conf ] ;then
        #check start.
        local dublicated_name=$(_format_conf $g_conf |awk '{print$1}' |uniq -d)
        if [[ -n $dublicated_name ]] ;then
            echo "group name conflicted: $(_red "$dublicated_name")"
            exit 1
        fi
        #echo "$(_format_conf $g_conf)"
        index_name_array=("host group name" "ssh user" "ssh port" "backend group" "bknd execute mode" "host ip list")
        #read line with 7 fields
        while read f1 f2 f3 f4 f5 f6 f7 ;do
            missing_info=''
            #skip empty line
            local group_info=($f1 $f2 $f3 $f4 $f5 $f6 $f7)
            for index in {1..5} ;do 
                if [[ -z ${group_info[$index]} ]] ;then
                    local missing_info+=" ${index_name_array[$index]},"
                elif [[ $index -eq 2 ]] ;then 
                    if _check_port ${group_info[$index]} ;then
                        :
                    else 
                        echo "group :$f1, illegal ssh port ${group_info[$index]} "
                        local check_stat=1 
                    fi
                elif [[ $index -eq 5 ]] && [[ ${group_info[$index]} == "--" ]] ;then
                    local grp_file=$(dirname $0)/conf/$f1'.grp'
                    if [[ -f $grp_file ]] ;then
                        for i in  $(_format_conf $grp_file);do
                            if ! _check_ip $i ;then
                                echo "group :$f1, illegal ip format $i"
                                local check_stat=1 
                            fi
                        done
                    fi
                fi 
            done
            [[ -n $missing_info ]] && echo "group :$f1, missing $missing_info info" && local check_stat=1
        done  << EOF
$(_format_conf $g_conf)
EOF
        if [[ $check_stat -ne 1 ]] ;then
            _info "host group config file check ok."
            return 0
        else
            _error "host group config file check error."
            return 1
            #exit 1
        fi 
    else
        echo "host list file not fond."
    fi
}
function _blk_conf_check(){
    _blue "${FUNCNAME[@]} is on the way ... 0_="
}
function _job_conf_check(){
    _blue "${FUNCNAME[@]} is on the way ... 0_="
}

##############################################################################################
# user input check
##############################################################################################
#check host,blk,fio jobs list from input
#group name expansion and check

function _get_all_host_group(){
    host_group_list+=$(_format_conf $g_conf \
        |awk '{print$1}' \
        |sed ':label;N;s/\n/\ /;b label'
    )
}
function _group_check(){
    if [[ $1 == "tmp_specified_host" ]] ;then
        return 0
    fi
    # $1 host_group_name
    local host_group_name=$1
    local index_name_array=("host group name" "ssh user" "ssh port" "backend group" "backend script execute mode" "host ip list")
        #get group info from conf file with keywords in column one.
        local group_info=($(_format_conf $g_conf |grep ^$host_group_name[' '] ))
                # 1. group_info check, more then 4 culumns, 
                if [[ ${#group_info[@]} -gt 5 ]] ;then
                # 2. if no missing columns, store into global array
                       VALID_HOST_GROUP_INFO_ARRAY[$host_group_name]=${group_info[@]}
                             HOST_GROUP_USER_ARRAY[$host_group_name]=${group_info[1]}
                             HOST_GROUP_PORT_ARRAY[$host_group_name]=${group_info[2]}
                             HOST_GROUP_BKND_ARRAY[$host_group_name]=${group_info[3]//,/ }
                          HOST_GROUP_SH_MODE_ARRAY[$host_group_name]=${group_info[4]}
                    # find ip list in config dir "conf/xxx.grp"
                    if [[ ${group_info[5]} == '--' ]] ;then
                        local host_conf=$(dirname $0)/conf/$host_group_name".grp"
                        if [[ -f $host_conf ]] ;then
                            # reformat hostname.
                            HOST_GROUP_IP_LIST_ARRAY[$host_group_name]=$(_uniq_list $(_format_conf $host_conf ) | sed 's/-/_/g' )
                        else
                            _warn "host group config file: $g_conf, group name: \"$host_group_name\" , ip list file: \"$host_conf\" is missing "
                        fi
                    else
                          HOST_GROUP_IP_LIST_ARRAY[$host_group_name]=$(_uniq_list ${group_info[5]//,/ })
                    fi
    #echo ${HOST_GROUP_IP_LIST_ARRAY[$host_group_name]}
                else
                # if group info lost, skip or exit
                # 3. check from last, find last missing info index, and print its name.
                    for index in {1..5} ;do
                       [[ -z ${group_info[$index]} ]] && _warn "host group config file: $g_conf, group name: \"$host_group_name\" , ${index_name_array[$index]} info missing!"
                    done
                    grp_stat=1
                    # remove from host_group_list
                    host_group_list=${host_group_list/$host_group_name/}
                    _error_interrupt
                fi
            #group check done
}
function _host_group_check(){
#veirify all host group from input, then store in array
# grp_stat, 0: ok, 1: part failed, 2: all failed.
    grp_stat=0
    if [[ -n ${host_group_list} ]] ;then
        host_group_list=$(_uniq_list $host_group_list)
        #calculating group name and ip list
        # remove exceptions
        if [[ -n $x_group_list ]] ;then
            x_group_list=$(_uniq_list $x_group_list)
            for x_group in $x_group_list ;do
                host_group_list=${host_group_list/$x_group/}
            done
        fi
    #check group result after remove X group
        if [[ -n ${host_group_list// /} ]] ;then
            #validate every host group availability
            for host_group_name in ${host_group_list} ;do 
                _group_check $host_group_name 
            done
            #after group check, if valid host group exists
            if [[ -z ${host_group_list// /} ]] ;then
                grp_stat=2
                echo "no valid host group!"
            fi
        else
        #no valid group left after remove X group
            _red "no valid host group!"
            grp_stat=2
        fi
    else
    #no group input captured
        grp_stat=2
        _red "no host group name revived."
        exit 1
    fi
}
function _show_group_info(){
            local tmpfile_group_info=$(mktemp)
            echo "NAME,USER,PORT,BKND,MODE,IP" >$tmpfile_group_info 
            _format_conf $g_conf |sed -e 's/,/\+/g' -e 's/\ /,/g' >>$tmpfile_group_info
            bash $(dirname $0)/tools/catcsv.sh $tmpfile_group_info
            rm -f $tmpfile_group_info
}
function _job_group_check(){
#verify job group and get fio arguments merged, then store in array
# job_stat, 0: ok, 1: part failed, 2: all failed.
    job_stat="0"
    #get default job info array
    DEFAULT_INFO=($(_format_conf $j_conf |grep ^DEFAULT[' '] ))
        #check args were double quoted
        [[ ${DEFAULT_INFO[6]} =~ '"' ]] && \
        DEFAULT_INFO[6]=$(_format_conf $j_conf |grep ^DEFAULT[' '] |cut -d'"' -f2) || \
        DEFAULT_INFO[6]="${DEFAULT_INFO[6]//,/ }"
    #an array of element names for all job group
    index_name_array=("job group name" "job runtime" "test data size" "block size" "test pattern" "inherit_DEFAULT" "customized fio args")
    #list checking work
    if [[ -n ${job_group_list} ]] ;then
        job_group_list=$(_uniq_list $job_group_list)
        # 01 every job group, info check.
        for job_group_name in $job_group_list ;do
            # get its info
            if _format_conf $j_conf | grep -q ^$job_group_name[' '] ;then
                :
            else
                # skip invalid
                job_group_list=${job_group_list//$job_group_name/}
                continue
            fi
            job_group_info=($(_format_conf $j_conf |grep ^$job_group_name[' '] ))
                #check args were double quoted
                [[ ${job_group_info[6]} =~ '"' ]] && \
                job_group_info[6]=$(_format_conf $j_conf |grep ^$job_group_name[' '] |cut -d'"' -f2) || \
                job_group_info[6]="${job_group_info[6]//,/ }"
            # 1. job group info must more than 6 element, index 0-5.
            if [[ ${#job_group_info[@]} -lt 6 ]] ;then
                # check failed, remove it from blk group list, update grp_stat
                job_stat=1
                job_group_list=${job_group_list/$job_group_name/}
                # check missing array element. check from the last, which element is missing.
                # if index2 is missing index3 will be take as index2, so always find the last missing index, index 1-5
                for index in {1..5} ;do
                   [[ -z ${job_group_info[$index]} ]] && _warn "job group config file: $j_conf, $job_group_name: ${index_name_array[$index]} info missing!"
                done
                _error_interrupt
            else
            # 2. if info ok, args calculating, check if use default
                # if use default, merge default fio args
                if [[ ${job_group_info[5]} == "True" ]] ;then 
                    # DEFAULT arg iterm check and add to this job group
                    for iterm in ${DEFAULT_INFO[6]} ;do
                        [[ "${job_group_info[6]}" =~ "${iterm%%=*}" ]] || job_group_info[6]+=" ${iterm}"
                    done
                # if not use default, doing nothing, just keep its own.
                fi
            # 3. after calculation, save valid group info to global arrays for common access
               VALID_JOB_INFO_ARRAY[$job_group_name]="${job_group_info[@]:0:7}"
                  JOB_RUNTIME_ARRAY[$job_group_name]="${job_group_info[1]}"
                JOB_DATA_SIZE_ARRAY[$job_group_name]="${job_group_info[2]}"
                       JOB_BS_ARRAY[$job_group_name]="${job_group_info[3]//,/ }"
                  JOB_PATTERN_ARRAY[$job_group_name]="${job_group_info[4]//,/ }"
                     JOB_ARGS_ARRAY[$job_group_name]="${job_group_info[6]}"
            fi
            # options should be started with '-'
            for iterm in ${job_group_info[6]} ;do
                [[ ${iterm:0:1} != '-' ]] && _yellow "job group name: $job_group_name, loose fio option found: \"${iterm}\"" && _timeout 15
            done
        #   04 exit or skip if any job group info missing.
                job_stat="1"
        #  group check done
        done
    #   after group check, if valid job groups exists
        if [[ -z ${job_group_list// /} ]] ;then
            job_stat="2"
            _red "no valid job group!"
            exit 1
        fi
        [[ $(echo $job_group_list |wc -w) -gt 1 ]] && multy_job_group="True"
    #
    else
        job_stat="2"
        _red "No job group name recived."
        exit 1
    fi
}
function _blk_group_check(){
#verify blk group from input, then store in array
# blk_stat, 0: ok, 1: part failed, 2: all failed.
    blk_stat="0"
    #none empty list
    if [[ -n ${blk_group_list// /} ]];then
        blk_group_list=$(_uniq_list $blk_group_list)

        # every blk, group info check
        for blk_group_name in $blk_group_list ;do
            # 1. if found in conf
#echo "check result"
#_format_conf $b_conf 
#_format_conf $b_conf |grep ^$blk_group_name[' ']
#echo "pre check result"
#_format_conf $b_conf |grep ^[' ']*$blk_group_name[' ']
#sleep 30
            if _format_conf $b_conf |grep -q ^[' ']*$blk_group_name[' '] ;then
            # 2. device list existence
                #get blk_list info put in a array
                blk_group_info=($(_format_conf $b_conf |grep ^$blk_group_name[' '] ))
#echo "${blk_group_info[@]}"
                if [[ -z ${blk_group_info[1]} ]] ;then
                    #no device list, remove from blk group list, update blk group stat
                    blk_stat="1"
                    blk_group_list=${blk_group_list/$blk_group_name/}
                    # give info which is missing.
                    _error "blk group: $blk_group_name, device list info is missing!"
                    # if test with the rest group
                    _error_interrupt
                else
            # 3. after check no part missing, store device list of this blk group in global array.
                BLK_DEV_ARRAY[$blk_group_name]=${blk_group_info[1]//,/ }
                fi
            elif [[ -f $(dirname $0)/conf/$blk_group_name".blk" ]] ;then
                # check blk config and add blk info to array 
                blk_group_info[1]=$(_format_conf $(dirname $0)/conf/$blk_group_name".blk")
                blk_group_info[1]=$(_uniq_list ${blk_group_info[1]})
                [[ -n ${blk_group_info[1]//,/} ]] && BLK_DEV_ARRAY[$blk_group_name]=${blk_group_info[1]//,/ }
            # 1.2 name missing in conf
            else
            #remove the invalid group which its name not exist in conf
                _warn "blk config file: $b_conf, $blk_group_name: device list info is missing!"
                blk_stat="1"
                blk_group_list=${blk_group_list/$blk_group_name/}
                # skip missing test with the rest group
                _error_interrupt
            fi
            #sleep 30
        #check done
        done
        # after all checked, if available blk_group exist
        if [[ -z ${blk_group_list// /} ]] ;then
            blk_stat="2"
            _red "no valid blk groups."
        fi
        [[ $(echo $blk_group_list |wc -w) -gt 1 ]] && multy_blk_group="True"
    else
    #empty list
    #[[ -f $(dirname $0)/conf/ ]]
        #if [[ $no_sys_blk != "True" ]] ;then
            blk_stat="2"
            _red "no blk group name recived."
            exit 1
        #fi
    fi
}
function _recover_point_check(){
    # conflict check.
    [[ $recover_test == "True" ]] && [[ $round_retest == "True" ]] && echo "Parameter confusion!" && exit 1
    # recover or retest.
    if  [[ $recover_test == "True" ]] || [[ $round_retest == "True" ]] ;then 
        if [[ $recover_test == "True" ]] ;then
            # recover_blk_group_name might be empty 
            # recover_job_batch_index cannot be empty 
            if [[ -z $recover_job_batch_index ]] ;then
                # check recover log file 
                if [[ ! -f $output_dir/recover.log ]] ;then
                    _yellow "Recover log file: \"$output_dir/recover.log\" is missing!"
                    echo "Perhapes the test ended too early or it's all done, You can restart the test but it cant't be recovered."
                    exit 1
                fi
                recover_info=$(sed -n 1p $output_dir/recover.log)
                recover_blk_group_name=${recover_info%,*}
                recover_job_batch_index=${recover_info##*,}
            fi
            # give recover info 
            _blue "Test recovering..."
        elif [[ $round_retest == "True" ]] ;then 
            _blue "Round retest starting..."
        fi
        # check format and give info 
        if [[ ${recover_job_batch_index//[^0-9,-]/} != $recover_job_batch_index ]] ;then
            echo "$recover_job_batch_index: recover_job_batch_index format error!"
            exit 1
        fi
        [[ -z $recover_blk_group_name ]] && local b_name="omited" || local b_name="\"$recover_blk_group_name\""
        _blue "recover point: blk_group_name: $b_name, job_batch_index: \"$recover_job_batch_index\""
    fi 
}
function _recover_blk_group(){
                # recover 
                [[ $recover_test == "True" ]] && [[ -n $recover_blk_group_name ]] && [[ $blk_group_name != $recover_blk_group_name ]] && continue 
                # clean recover info after recovery
                [[ $recover_test == "True" ]] && recover_blk_group_name=""
                #_blue "recover from blk group: $blk_group_name"

                # round retest 
                [[ $round_retest == "True" ]] && [[ -n $recover_blk_group_name ]] && [[ $blk_group_name != $recover_blk_group_name ]] && continue 
}
function _recover_job_batch(){
                # recover  
                [[ $recover_test == "True" ]] && [[ -n $recover_job_batch_index ]] && [[ $job_batch_index != $recover_job_batch_index ]] && continue 
                # clean recover info after recovery
                [[ $recover_test == "True" ]] && recover_job_batch_index="" && recover_test="False"
                # set new recover_info 
                echo "$blk_group_name,$job_batch_index" > $output_dir/recover.log
                #_blue "recover test batch from job Round_No: $job_batch_index"

                # round retest 
            if [[ ${recover_job_batch_index/-/} == ${recover_job_batch_index} ]] ;then 
                [[ $round_retest == "True" ]] && [[ -n $recover_job_batch_index ]] && [[ $job_batch_index != $recover_job_batch_index ]] && continue 
            else 
                [[ $round_retest == "True" ]] && [[ -n $recover_job_batch_index ]] && [[ $job_batch_index -lt ${recover_job_batch_index%-*} ]] && continue 
                [[ $round_retest == "True" ]] && [[ -n $recover_job_batch_index ]] && [[ $job_batch_index -gt ${recover_job_batch_index#*-} ]] && continue 
            fi 
}
##############################################################################################
# task preparation.
##############################################################################################
# 1. a blk group can not be shared for different scale of fio test at the same time,
#    but the job groups and the host groups can be shared by different scale of test.
# 2. build a job batch list with all available job groups, contains each round of job.
# 3. distribute jobs to host groups, different host groups may have different user and port settings
function _rbd_expansion(){
    # $1 host_group_name 
    # $blk_group_name set 
    local all_ip_list=''
    if [[ -z $1 ]] ;then
        for i in $host_group_list;do
            all_ip_list+=" ${HOST_GROUP_IP_LIST_ARRAY[$i]}"
        done
    else
        all_ip_list="${HOST_GROUP_IP_LIST_ARRAY[$1]}"
    fi 
    all_ip_list=$(_uniq_list $all_ip_list)
    # HOST_GROUP_IP_LIST_ARRAY
    # HOST_GROUP_RBD_DEV_ARRAY 
    # cleanning up array for current host group 
# if an array declared in a function, it will a local array for bash shell.
    #unset HOST_GROUP_RBD_DEV_ARRAY 
    #declare -A HOST_GROUP_RBD_DEV_ARRAY # host_name 
    for k in ${HOST_GROUP_RBD_DEV_ARRAY[*]};do
        [[ -n $k ]] && HOST_GROUP_RBD_DEV_ARRAY[$k]=''
    done
    local rbd_list=${BLK_DEV_ARRAY[$blk_group_name]} 
    #local hst_list=${HOST_GROUP_IP_LIST_ARRAY[$1]}
    # count rbd_numbere
    local rbd_nu=$(echo $rbd_list |wc -w)
    # count host number 
    #local hst_nu=$(echo $hst_list |wc -w)
    local hst_nu=$(echo $all_ip_list |wc -w)
    # 
    if [[ $hst_nu -ge $rbd_nu ]] ;then 
        # rbd less then host 
        local dsb_nu=1
    else
        local dsb_nu=$(($rbd_nu / $hst_nu))
    fi
    # 
    #echo "rbd:$rbd_nu hst:$hst_nu dsb:$dsb_nu"
    local host_name=''
    for host_name in $all_ip_list ;do
        HOST_GROUP_RBD_DEV_ARRAY[$host_name]=''
    done
    for host_name in $all_ip_list ;do
        #echo "host: $host_name"
        for rbd_name in $rbd_list ;do
            # rbd001 
            #echo "rbd: $rbd_name hst rbd nu:$(echo ${HOST_GROUP_RBD_DEV_ARRAY[$host_name]} |wc -w)"
            if test $(echo ${HOST_GROUP_RBD_DEV_ARRAY[$host_name]} |wc -w) -lt $dsb_nu ;then 
                HOST_GROUP_RBD_DEV_ARRAY[$host_name]+=" $rbd_name" 
                rbd_list=${rbd_list/$rbd_name/}
            else
                break 
            fi
        done
    done
    if [[ $(( $rbd_nu % $hst_nu )) -ne 0 ]];then
        #
        for host_name in $all_ip_list;do
            #
            for rbd_name in $rbd_list ;do
                HOST_GROUP_RBD_DEV_ARRAY[$host_name]+=" $rbd_name" 
                rbd_list=${rbd_list/$rbd_name/}
                break 
            done
        done
    fi
    if _verbose || [[ $round_list == "True" ]] ;then 
        if [[ -n $1 ]] ;then 
            local i="host group: $host_group_name" 
        else
            #_blue "\ngroup parallel test expansion"
            local i="host groups: ${host_group_list// /, }" 
        fi 
        _yellow "\nRBD Distribution Info:"
        _blue "blk group: $blk_group_name, $i"
#echo keys: ${!HOST_GROUP_RBD_DEV_ARRAY[*]}
#echo host: $all_ip_list
        for k in ${all_ip_list};do
            printf "%-24s%-15s\n" "host: ${k}" "| ${HOST_GROUP_RBD_DEV_ARRAY[$k]}"
        done
        echo ''
    fi
}
function _show_rbd_expansion(){
    #test _rbd_expansion 
    if [[ $rbd_mode == "True" ]] ;then 
        if [[ $group_mode == "single" ]];then
            for blk_group_name in $blk_group_list;do 
                for host_group_name in $host_group_list;do
                    _rbd_expansion $host_group_name 
                done
            done
        else
            _rbd_expansion 
        fi
    fi 
}
function _give_size(){
    #if [[ ${JOB_DATA_SIZE_ARRAY[$job_group_name]} == "none" ]] ;then
    #    :
    if [[ ${JOB_DATA_SIZE_ARRAY[$job_group_name]} == "random" ]] ;then
        :
    else
        echo "-size=${JOB_DATA_SIZE_ARRAY[$job_group_name]}"
    fi
}
function _give_runtime(){
    if [[ ${JOB_RUNTIME_ARRAY[$job_group_name]} != "none" ]] ;then
        echo "-runtime=${JOB_RUNTIME_ARRAY[$job_group_name]}"
    fi
}
function _give_bs(){
    if [[ $BS != "none" ]] ;then
        echo "-bs=$BS"
    #else
    #    :
    fi
}
function _fio_job_expansion(){
# generate job batch for blk group to build scale test, and send to  host group to execute.
# expanted based on: job_group_name --> BS --> PATTERN 
#                    they will be stored in a global name array.
    total_round=0
    local runtime_sum=""
    declare -A ground gtime
    _verbose && _yellow "job group expansion:"
    for job_group_name in $job_group_list ;do
        #count round number and basic time costs for group.
        ground[$job_group_name]=0
        gtime[$job_group_name]=0
#        echo ${VALID_JOB_INFO_ARRAY[$job_group_name]}
        for BS in ${JOB_BS_ARRAY[$job_group_name]} ;do
            for PATTERN in ${JOB_PATTERN_ARRAY[$job_group_name]} ;do
                #update round number
                total_round=$(($total_round + 1))
                ground[$job_group_name]=$(( ${ground[$job_group_name]} + 1 ))
                #update time for group
                gtime[$job_group_name]=$(( ${JOB_RUNTIME_ARRAY[$job_group_name]} * ${ground[$job_group_name]} / 60 )) 
                #update runtime_sum
                [[ -z $runtime_sum ]] && runtime_sum=${JOB_RUNTIME_ARRAY[$job_group_name]}  || runtime_sum=$((${JOB_RUNTIME_ARRAY[$job_group_name]} + $runtime_sum ))
                #pdebug info
                _verbose "expansion" && _waiting 5 "reading" 
                #store job batch in global list
                JOB_BATCH_ARRAY[$total_round]="\
fio \
$(_give_runtime) \
$(_give_size) \
$(_give_bs) \
-rw=$PATTERN \
${JOB_ARGS_ARRAY[$job_group_name]} "
                JOB_BATCH_NAME_ARRAY[$total_round]=$job_group_name-$BS-$PATTERN
            done
        done
    done
    # round info 
    if _verbose || [[ $round_list == "True" ]] ;then 
        _yellow "job time caculation:"
        echo -e "\tall job group will lunch $total_round fio jobs, and costs $(($runtime_sum / 60 + $(($total_round/ 2)) )) minites on a single host at least.\n"
        for job_group_name in $job_group_list ;do
            echo -e "\tjob group: \"$job_group_name\" will lunch ${ground[$job_group_name]} round of jobs, costs $((${gtime[$job_group_name]} + $((${ground[$job_group_name]}/2)) )) minites at least."
        done
        # make a list of job batch info 
        local tmpfile_expansion=$(mktemp -p $tmpfile_dir)
        local title="NO"
        local batch="PATTERN"
        if [[ $total_round -le 10 ]];then 
            for index in $(seq 1 $total_round);do
            #
                title+=",$index"
                batch+=",${JOB_BATCH_NAME_ARRAY[$index]}"
            done
            echo -e "$title\n$batch" >$tmpfile_expansion
        else
            for index in $(seq 1 $total_round);do
                echo "$index,${JOB_BATCH_NAME_ARRAY[$index]}" >> $tmpfile_expansion 
            done
        fi 
        _yellow "round list:"
        $(dirname $0)/tools/catcsv.sh $tmpfile_expansion | sed 1d 
        rm -f $tmpfile_expansion 
        [[ $round_list == "True" ]] && _show_rbd_expansion && exit 0 || _waiting 5 "reading" 
    fi
}
##############################################################################################
# cluster test action decomposition
##############################################################################################
# this part function by assigning different tasks to different individuals
function _parse_host_info(){
# input : host_group_name
# parsing from global array 
#     host_user, host_port, ip_list,
#     fio_cmd, 
#     job_group_name bs pattern 
    if [[ -z $1 ]] ;then
        if [[ -n $host_group_name ]] ;then
            current_host_group="$host_group_name"
        else
            echo "${FUNCNAME[@]} : no host group name recived"
            return 1
        fi
    else
        current_host_group="$1"
        host_user="${HOST_GROUP_USER_ARRAY[$current_host_group]}"
        host_port="${HOST_GROUP_PORT_ARRAY[$current_host_group]}"
        bknd_grps="${HOST_GROUP_BKND_ARRAY[$current_host_group]}"
        bknd_mode="${HOST_GROUP_SH_MODE_ARRAY[$current_host_group]}"
          ip_list="${HOST_GROUP_IP_LIST_ARRAY[$current_host_group]}"
#echo $ip_list
          fio_cmd="${job_batch}"
         num_jobs=$(echo $fio_cmd |awk -F'-numjobs=' '{print$2}' |awk '{print$1}')
         [[ -z $num_jobs ]] && num_jobs=x
   job_group_name="${JOB_BATCH_NAME_ARRAY[$job_batch_index]%%-*}"
         job_name="${JOB_BATCH_NAME_ARRAY[$job_batch_index]#*-}"
        # give info
        echo " host group : $(_yellow "$current_host_group") $(_local_unquiet "  host amount: $(echo $ip_list |wc -w) ") "
        #[[ -n $blk_group_name ]] && _unquiet " blk group:\"$blk_group_name\",job batch num:\"$job_batch_index\",job group name:\"$job_group_name\",job pattern:\"$job_name\""
        if [[ -n $blk_group_name ]] ;then 
            [[ -n $job_group_name ]] && local parse_runtime_info="runtime: ${JOB_RUNTIME_ARRAY[$job_group_name]}"
            _local_unquiet " blk group:\"$blk_group_name\",  blk amount:\"$(echo ${BLK_DEV_ARRAY[$blk_group_name]} |wc -w )\",  blk test mode: $(_yellow $test_mode)"
            _local_unquiet " job group:\"$job_group_name\",  job pattern:\"$job_name\",  $parse_runtime_info "
            #echo ${!JOB_RUNTIME_ARRAY[@]}
            #echo $job_group_name 
        fi
        if [[ -z ${host_user// /} ]] || [[ -z ${host_port// /} ]] || [[ -z ${ip_list// /} ]] ;then
            _error "${FUNCNAME[@]}: group: \"$1\", ssh login info is missing."
            continue || exit 1
        fi
        #remove x_host list from group ip_list
        if [[ -n $x_host_list ]] ;then
            for xh in $x_host_list ;do
                ip_list=${ip_list/$xh/}
            done
        fi
        # info
        if _verbose "groupinfo" ;then
            _waiting 5 "reading"
            if [[ $send_fio == "True" ]] && [[ -n $blk_group_name ]] ;then
                echo "blk list : ${BLK_DEV_ARRAY[$blk_group_name]}"
                _waiting 5 "reading blk info"
            fi
        fi
    fi
}
##############################################################################################
# actions on a host
##############################################################################################
function _ping_check(){
    [[ $no_ping == "True" ]] && return 0
    ping -c1 $host_ip  &>/dev/null 
    local ping_stat=$?
    return $ping_stat
}
function _ssh_send(){
#send command info to host when ssh_user, ssh_ip, ssh_port was set
    if [[ $# -lt 1 ]] ;then
        _warn "${FUNCNAME[@]} : no command info to send!" 
        return 1
    else
        #if expect -v &>/dev/null ;then 
        #    $(dirname $0)/bin/login/expect_ssh2vm.exp $host_user $host_ip $host_port 'www.123.com' "$@"
            #exddpect -v &>/dev/null && expect bin/expect_ssh2vm.exp $host_user $host_ip $host_port $host_pwd "$@"
        #else 
            #eval _ssh_cmd -o ConnectTimeout=$ssh_timeout \
            #        -l $host_user $host_ip \
            #        -p $host_port "${cmd_prefix}$@"
            ssh -n -q $old_ssh_alias \
                -o StrictHostKeyChecking=no \
                -o ConnectTimeout=$ssh_timeout \
                -o PubkeyAuthentication=yes \
                -o PasswordAuthentication=no \
                -o BatchMode=yes \
                -l $host_user $host_ip \
                -p $host_port "${cmd_prefix}$@"
        #fi 
        local cmd_stat=$?
        [[ $cmd_stat -ne 0 ]] && _cmdfail
        [[ $pdebug == "True" ]] && _record_cmd "$cmd_stat" "${cmd_prefix}$@"
        return $cmd_stat 
    fi
}
function _ssh_check(){
    _ssh_send "/bin/true"
    local ssh_stat=$?
    return $ssh_stat
}
function _send_file(){
    if [[ -n $file_group_list ]] ;then
        _unquiet "  $host_ip send files..."
        if [[ $quiet_mode == "True" ]] ;then
            _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $file_group_list $host_user@$host_ip:$file_group_destination &>/dev/null 
            local scp_stat=$?
            echo "  $host_ip stat: $scp_stat"
            _update_check_stat $scp_stat $tmpfile_exec 
        else
            _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $file_group_list $host_user@$host_ip:$file_group_destination && echo "  $host_ip done"
            local scp_stat=$?
            _update_check_stat $scp_stat $tmpfile_exec 
        fi
    #else
    #    [[ $send_fio == "True" ]] && _unquiet "    no files to copy."
    fi
}
function _harvest_file(){
    if [[ -n ${harvest_file_group_list//,/} ]] ;then
        _check_output_dir
        local harvest_dir=$output_dir/$host_ip
        [[ -d $harvest_dir ]] || mkdir -p $harvest_dir &>/dev/null
        _unquiet "  $host_ip harvest files..."
        # one file or dir to harvest
        if [[ ${harvest_file_group_list//,/} == ${harvest_file_group_list} ]] ;then
            if [[ $quiet_mode == "True" ]] ;then
                eval _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $host_user@$host_ip:$harvest_file_group_list $harvest_dir/ &>/dev/null                                                        
                local hvst_stat=$?
                echo "  $host_ip stat: $hvst_stat"
                _update_check_stat $hvst_stat $tmpfile_exec 
            else
                eval _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $host_user@$host_ip:$harvest_file_group_list $harvest_dir && echo "  $host_ip done"
                local hvst_stat=$?
                _update_check_stat $hvst_stat $tmpfile_exec 
            fi
        # multy files
        else
            if [[ $quiet_mode == "True" ]] ;then
                eval _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $host_user@$host_ip:{$harvest_file_group_list} $harvest_dir/ &>/dev/null                                                        
                local hvst_stat=$?
                echo "  $host_ip stat: $hvst_stat"
                _update_check_stat $hvst_stat $tmpfile_exec 
            else
                eval _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $host_user@$host_ip:{$harvest_file_group_list} $harvest_dir && echo "  $host_ip done"
                local hvst_stat=$?
                _update_check_stat $hvst_stat $tmpfile_exec 
            fi
        fi
    #else
    #    [[ $send_fio == "True" ]] && _unquiet "    no files to copy."
    fi
}
function _send_cmd(){
    #send cmd to host and format output.
    if [[ -n $CMD ]] ;then
        if [[ $quiet_mode == "True" ]] ;then
            _ssh_send "$CMD " &>/dev/null 
            local cmd_stat=$?
            echo "  $host_ip stat: $cmd_stat"
            _update_check_stat $cmd_stat $tmpfile_exec 
        else 
            if  [[ $p_exec == "True" ]] ;then 
                local tmpfile_exec_host_out=$(mktemp -p $tmpfile_dir)
                #use virtual terminal and recive tty input.
                # echo "$host_ip :"
                _ssh_fg -o ConnectTimeout=$ssh_timeout -l $host_user $host_ip -p $host_port "${cmd_prefix}$CMD" 2>&1 |tee $tmpfile_exec_host_out
                local cmd_stat=$?
                _update_check_stat $cmd_stat $tmpfile_exec 
            else 
                local tmpfile_exec_host_out=$(mktemp -p $tmpfile_dir)
                # do not merge output 
                _ssh_send " echo -e \" HOST:\e[34m\$HOSTNAME \e[0m \" "
                _segline "$host_ip  stdout"
                _ssh_fg -o ConnectTimeout=$ssh_timeout -l $host_user $host_ip -p $host_port "${cmd_prefix}$CMD" 2>&1 |tee $tmpfile_exec_host_out
                local cmd_stat=$?
                _update_check_stat $cmd_stat $tmpfile_exec 
                _segline "$host_ip cmd end"
                #echo "$host_ip empty $cmd_stat" >> $tmpfile_exec_diff 
                #touch /tmp/empty 
            fi
        #if [[ -n $(cat $tmpfile_exec_host_out) ]] ;then _green not empty ;else  echo empty log file ;fi
            # empty output 
            if [[ $(wc -l <$tmpfile_exec_host_out) -eq 0 ]] ;then 
                    echo "$host_ip $tmpfile_dir/empty $cmd_stat" >> $tmpfile_exec_diff 
                    touch $tmpfile_dir/empty 
            # not empty output 
            else
                local content_sum=$(cat $tmpfile_exec_host_out |md5sum |awk '{print$1}')
                echo "$host_ip $tmpfile_dir/$content_sum $cmd_stat" >> $tmpfile_exec_diff 
                touch $tmpfile_dir/$content_sum
                flock $tmpfile_dir/$content_sum cat $tmpfile_exec_host_out > $tmpfile_dir/$content_sum 
            fi 
            rm -rf $tmpfile_exec_host_out 
        fi 
    #else
    #    _unquiet "    no command to run."
    fi
}
##############################################################################################
function _host_ssh_script(){
    local host_ip=$1
    # running script on remote host through stdin.
        #local script_file=$1
        #local script_args="${@:2}"
    if [[ -f $script_file ]];then
        if _ping_check ;then
        # network and ssh connection test.
            if _ssh_check ;then
                if [[ $quiet_mode == "True" ]] ;then
                    cat $script_file | _ssh_fg -o ConnectTimeout=$ssh_timeout -l $host_user $host_ip -p $host_port "${cmd_prefix}cat - |bash -s \"$script_args\"" &>/dev/null 
                    local script_stat=$?
                    echo "  $host_ip stat: $script_stat"
                    _update_check_stat $script_stat $tmpfile_script_host_out 
                else
    #                echo "1:$1 2:$2"
                    cat $script_file | _ssh_fg -o ConnectTimeout=$ssh_timeout -l $host_user $host_ip -p $host_port "${cmd_prefix}cat - |bash -s \"$script_args\""
                    local script_stat=$?
                    _update_check_stat $script_stat $tmpfile_script_host_out 
                fi
            else
                _sshfail
                _update_check_stat 1 $tmpfile_script_host_out 
            fi
        else
            _pingfail
            _update_check_stat 1 $tmpfile_script_host_out 
        fi
    else
        _red "script file: $script_file missing."
    fi
}
function _group_ssh_script(){
# input :
#        $1 host_group_name 
#        $2 script file name 
#        $3 script_argument_list
#          the output file name.
    _tmp_quiet "on"
        _yellow "exec script:"
        _parse_host_info "$1"
        tmpfile_script_host_out=$(mktemp -p $tmpfile_dir)
        #echo 0 > $tmpfile_script_host_out 
        local script_file=$2
        local script_args="${@:3}"
        #for host_ip in $ip_list;do 
            if [[ $p_exec == "True" ]] || [[ $send_fio == "True" ]];then
                host_exec_function="_host_ssh_script"
                _run_in_concurrent_pipe
                #_host_ssh_script $2 "$3" &
            else
                for host_ip in $ip_list;do 
                    _host_ssh_script $host_ip #$2 "$3"
                done
            fi
    #        echo "1:$1 2:$2 3:$3"
        #done && wait 
        _confirm_check_stat $tmpfile_script_host_out
        rm -rf $tmpfile_script_host_out
        _unquiet "$1: execute script done."
    _tmp_quiet "off"
}
function _host_ssd_cpid(){
    #
    local host_ip=$1
        #for host_ip in $ip_list;do 
            if _ping_check ;then
                # network and ssh connection test.
                timeout $[ssh_timeout * 2] $(dirname $0)/tools/sshpass -p $ssh_passwd ssh-copy-id -o StrictHostKeyChecking=no -o ConnectTimeout=$ssh_timeout $host_user@$host_ip -p $host_port 
                local init_stat=$?
                [[ $init_stat -ne 0 ]] &&  _sshfail
                _update_check_stat $init_stat $tmpfile_init_host_out 
            else
                _pingfail 
                _update_check_stat 1 $tmpfile_init_host_out 
            fi #&
        #done && wait 
}
function _group_ssd_cpid(){
# input :
#        $1 host_group_name 
#        $2 ssh_passwd 
    if [[ -n $ssh_passwd ]] ;then 
        _tmp_quiet "on"
        _yellow "initializing ssh connections:"
        _parse_host_info "$1"
        tmpfile_init_host_out=$(mktemp -p $tmpfile_dir)
        #echo 0 > $tmpfile_init_host_out 
        _confirm_check_stat $tmpfile_init_host_out
        rm -rf $tmpfile_init_host_out
        _unquiet "$1: initialization done."
        _tmp_quiet "off"
    else
        echo "$1: ssh password not specified, skip initializing."
    fi
}
####################################################
# change for a different backend change this part
####################################################
function _record_bknd(){
# $1 host_group_name 
# works when bknd_grps/bknd_mode were set
# run script on certain host group and there output will be collected
# with a name like: 
# blk_group_name host_group_name job_group_name / pattern_name bknd_host script_name '.log' 
# collect backend info like tcmu and ceph
    _yellow "check bknd:"
    _parse_host_info "$1"
    # check bknd group name
    _verbose "bkndinfo" && _waiting 5 "reading"
    if [[ -n $bknd_grps ]] && [[ $bknd_grps != '--' ]] ;then 
        if [[ -n ${JOB_RUNTIME_ARRAY[$job_group_name]} ]] ;then 
            bknd_runtime="${JOB_RUNTIME_ARRAY[$job_group_name]}"
        else
            echo "job group $job_group_name, job runtime value empty!"
            exit 1
        fi
#---------|add needed info which you want to pass to your script|-----------------------
        local bknd_sh_pass_in="$output_dir $job_name $job_batch_index $bknd_runtime" 
        #local bknd_sh_pass_in=$bknd_runtime 
#---------------------------------------------------------------------------------------
        for bknd_grp in $bknd_grps ;do 
            # get host group info format 
            _group_check $bknd_grp 
            # get script info
            local bknd_mode=${HOST_GROUP_SH_MODE_ARRAY[$bknd_grp]}
            # check config file and content
            local bknd_sh_conf=$(dirname $0)/conf/$bknd_grp'.bsh'
            if [[ -f $bknd_sh_conf ]] ;then
                local bknd_sh_list=$(grep -vE "^$|^#" $bknd_sh_conf)
                if [[ -z ${bknd_sh_list// /} ]] ;then 
                    _red " bknd group : $bknd_grp script list conf empty, skiped."
                    continue
                fi 
            else
                _red " bknd group : $bknd_grp scripts list file missing, skiped."
                continue 
            fi
            echo " bknd group : $bknd_grp, script mode: $bknd_mode"
            # run script 
            if [[ $bknd_mode == "local" ]] ;then
                for i in ${bknd_sh_list} ;do
                    if [[ -f $i ]] ;then
                        # do not quote the parameters passing in 
                        echo "bash $i $bknd_sh_pass_in &>>$output_dir/bknd_${i//\//_}.log &" >>$output_dir/bknd_batch.log
                        if _verbose ;then 
                            bash -x $i $bknd_sh_pass_in &>>$output_dir/bknd_${i//\//_}.log &
                        else
                            #bash $i $bknd_sh_pass_in &>/dev/null &
                            bash $i $bknd_sh_pass_in &>>$output_dir/bknd_${i//\//_}.log &
                        fi
                    fi &
                done
            elif [[ $bknd_mode == "remote" ]] ;then 
                for i in ${bknd_sh_list} ;do
                    _group_ssh_script "$bknd_grp" "$i" "$bknd_sh_pass_in"
                done 
            fi
        done
    else
        echo " no bknd."
    fi
}
##############################################################################################
function _host_fio_check(){
    if _ping_check ;then
        # wait five secends, let fio start its jobs
        sleep 5
    else
        _pingfail 
        #_error_interrupt
    fi
    while _ssh_send 'ps aux |grep fio |grep filename |grep -qv grep ' ;do
        _verbose  hostinfo && _waiting 5 "reading"
        sleep 5
    done
    while _ssh_send 'ps aux |grep fio |grep rbdname |grep -qv grep ' ;do
        _verbose  hostinfo && _waiting 5 "reading"
        sleep 5
    done
}
function _send_fio(){
# send fio job and collect backend server info.
# no input
# works when:
#       blk_group_name was set
#       job batch info was set
#       host ssh info was set
#       bknd ssh info was set
#       and so on ...
    if [[ $send_fio == "True" ]] ;then
        if [[ ! -d $output_dir ]] ;then
            mkdir -p $output_dir
        fi
        # check if multy blkgroup/jobgroup
        [[ $multy_blk_group == "True" ]] && local path_flyover=$blk_group_name
        [[ $multy_job_group == "True" ]] && local path_flyover+=/$job_group_name 
        #log_dir
        if [[ -n path_flyover ]];then
            #
            log_dir="$output_dir/$path_flyover/$blk_group_name-$job_group_name-$current_host_group-${host_ip}"
        else 
            #
            log_dir="$output_dir/$blk_group_name-$job_group_name-$current_host_group-${host_ip}"
        fi
        # mkdir 
        [[ -d $log_dir ]] ||  mkdir -p $log_dir
        # record info for analysing
        [[ -f $log_dir/fio-batch'.log' ]] || echo -e "bs:\npattern:\nblk:\n" >$log_dir/fio-batch".log"
#sleep 20
        if _ssh_send "fio -v" &>/dev/null ;then
            # log on remote host
            _ssh_send "mkdir -p $log_dir"
            if [[ $rbd_mode == "True" ]] ;then 
                local host_blk_list=${HOST_GROUP_RBD_DEV_ARRAY[$host_ip]}
            else 
                local host_blk_list=${BLK_DEV_ARRAY[$blk_group_name]}
            fi 
#    pdebug=True 
#    _rbd_expansion 
#_marker "dev info"
#    echo ${HOST_GROUP_RBD_DEV_ARRAY[*]}
#    echo ${!HOST_GROUP_RBD_DEV_ARRAY[*]}
#    pdebug=False 
# sleep 30 
            for BLK in $host_blk_list 
            do
                # check blk file
                if _ssh_send "ls $BLK" &>/dev/null ;then
                    log_name=$job_name-${BLK//\//}".log.json"
                    # check sata disk with smartctl, nvme disks are not supported
                    local blk_name=${BLK##*/}
                    if [[ $rbd_mode == "True" ]] ;then
                        local tag=$num_jobs-${host_ip//-/_}-rbd  
                        # skip rbd check   
                        #:
                    elif [[ ${blk_name//nvme/} != "${blk_name}" ]] ;then
                        local tag=$num_jobs-${host_ip//-/_}-nvme 
                        # skip nvme
                        #:
                    else
                        local tag=$num_jobs-${host_ip//-/_}-hdd  
                        if [[ $(_ssh_send "smartctl -V &>/dev/null ;echo \$?") -eq 0 ]] ;then
                            # if smartmontools installed, check status.
                            blk_stats=$(_ssh_send "smartctl -H $BLK |grep 'SMART Health Status:' |awk '{print\$NF}' ")
                            [[ $blk_stats != "OK" ]] && _verbose &&"info: $host_ip \"$BLK\" smartmontools check failed."
                        fi
                    fi 
                elif [[ $rbd_mode == "True" ]] ;then
                    local tag=$num_jobs-$host_ip-rbd 
                    log_name=$job_name-${BLK//\//}".log.json"
                    #
                    _verbose && echo "log name: $log_name"
                else
                    #_red "host: $host_ip, blk or file : \"$BLK\" is not available on host!"
                    _devfail 
                    _verbose "jobinfo"
                fi
                # ready to send
                # update data size to a random value 
#---------|add random info which you want to add |-----------------------
                # local rand_arg="-iodepth=${RANDOM:0:1}"
#------------------------------------------------------------------------
                if [[ ${JOB_DATA_SIZE_ARRAY[$job_group_name]} == "random"  ]] ;then
                    local size_info="-size=$(($RANDOM%100+1))%"
                fi
                _verbose "jobinfo" && _waiting 15 "reading"
                    # wait previous 
                if [[ $rbd_mode == "True" ]];then 
                    [[ $test_mode == "single" ]] && _host_fio_check 
                    _ssh_send "$fio_cmd $size_info $rand_arg -rbdname=$BLK -name=$tag-$log_name  --output=$log_dir/$log_name &>>$log_dir/fio-err.log &"
                    #local fio_stat=$?
                    #_update_check_stat $fio_stat $tmpfile_exec
                    echo $job_batch_index $(date +%Y%m%d_%H:%M:%S) "$fio_cmd $size_info $rand_arg -rbdname=$BLK -name=$tag-$log_name   --output=$log_dir/$log_name &>>$log_dir/fio-err.log &" >>$log_dir/fio-batch".log"
                else 
                    [[ $test_mode == "single" ]] && _host_fio_check 
                    _ssh_send "$fio_cmd $size_info $rand_arg -filename=$BLK -name=$tag-$log_name  --output=$log_dir/$log_name &>>$log_dir/fio-err.log &"
                    #local fio_stat=$?
                    #_update_check_stat $fio_stat $tmpfile_exec
                    echo $job_batch_index $(date +%Y%m%d_%H:%M:%S) "$fio_cmd $size_info $rand_arg -filename=$BLK -name=$tag-$log_name  --output=$log_dir/$log_name &>>$log_dir/fio-err.log &" >>$log_dir/fio-batch".log"
                fi
                #record job bs, pattern, blk
                #bs info
                grep  "^bs:.*$" $log_dir/fio-batch".log" \
                |grep -q ",${job_name%-*}" \
                || sed -i "s/^bs:.*$/&\,${job_name%-*}/g" $log_dir/fio-batch".log"
                #pattern info
                grep  "^pattern:.*$" $log_dir/fio-batch".log" \
                |grep -q ",${job_name#*-}" \
                || sed -i "s/^pattern:.*$/&\,${job_name#*-}/g" $log_dir/fio-batch".log"
                #blk info
                grep "^blk:.*$" $log_dir/fio-batch".log" \
                |grep -q ",${BLK//\//}"  \
                || sed -i "s/^blk:.*$/&\,${BLK//\//}/g" $log_dir/fio-batch".log"
            #
            done
            #_update_check_stat 0 $tmpfile_exec
        else
            _update_check_stat 2 $tmpfile_exec
            _red "   $host_ip, fio is not ready !"
        fi 
    fi
}  
##############################################################################################
# job task delivery
##############################################################################################
# host
function _exec_with_job(){
# file , cmd , fio
    _send_file
    # action after send files
    _verbose && _blue "execut emode:$execute_mode"
    if [[ $execute_mode == "After" ]] ;then
        _unquiet "command running first."
        #command first
        _send_cmd && wait && _send_fio
    else
        _send_fio && wait && _send_cmd
    fi
}
# host
function _exec_only_oth(){
# file , cmd 
# exec in parallel too
    if [[ $p_exec == "True" ]] ;then
        _send_file && _send_cmd && _harvest_file & 
    else
    #send cmd sequentially
        _send_file
        _send_cmd
        _harvest_file
    fi
}
# host
function _exec_all(){
    host_ip=$1
    if _ping_check ;then
        #
        if _ssh_check ;then
        # file , cmd , fio
            if [[ $send_fio == "True" ]] ;then
                # put fio in bg, no need to wait and skip to next host immediately.
                _exec_with_job &
            else
            # file , cmd 
                _exec_only_oth
            fi
            _update_check_stat 0 $tmpfile_exec
        else
            _sshfail 
            _update_check_stat 1 $tmpfile_exec
        fi && wait
        #_unquiet "  host:$host_ip distribution done "
    else
        _pingfail 
        #_error_interrupt
        _update_check_stat 1 $tmpfile_exec
    fi
}
function _count_return(){
    # ip + filename + result sum value + cmd_stat 
    # calculate output of different host  
    local sum_list=$(awk '{print$2}' $tmpfile_exec_diff |sort -u )
    local sn=0
    for k in $sum_list ;do
        sn=$[sn + 1]
        # count content_sum 
        local host_k="$(grep $k $tmpfile_exec_diff |awk '{print$1}')"
        # give ip list which share a same content_sum
        local host_num_k=$(grep $k $tmpfile_exec_diff |wc -l )
        # output this type of content 
        _yellow "\n $host_num_k host returned as No. $sn"
        for i in ${host_k};do echo -ne "$i\t" ;done ;echo ""
        _segline "output No. $sn"
            cat $k 
        _segline "end of No. $sn "
        echo ""
        # rm tmpfile 
    done 
}
function _group_execute(){
# files/command/jobs was set
# blk_group_name was set (when lunch a test on cluster.)
# host_group_name was set
    _yellow "execute:"
    _parse_host_info "$1"
        local tmpfile_exec=$(mktemp -p $tmpfile_dir)
        [[ -z $tmpfile_exec_diff ]] && local tmpfile_exec_diff=$(mktemp -p $tmpfile_dir)
        # test host 
        #echo 0 > $tmpfile_exec
        local host_exec_function="_exec_all"
             #ping check
             if [[ $p_exec == "True" ]] || [[ $send_fio == "True" ]] ;then
                 #_exec_all &
                 _run_in_concurrent_pipe
             else
                for host_ip in $ip_list ;do
                     _exec_all $host_ip
                done #&& wait 
             fi
        # show different output 
        [[ $quiet_mode != "True" ]] && _count_return
        # clean up tmp file 
        for k in $(awk '{print$2}' $tmpfile_exec_diff) ;do 
            [[ -f /tmp/$k ]] && rm -f /tmp/$k
        done 
        #unset tmpfile_exec_diff 
#cat $tmpfile_exec_diff
        # read stat after all exec done
        _confirm_check_stat $tmpfile_exec
        rm -rf $tmpfile_exec $tmpfile_exec_diff
    _unquiet "$1: execute action done."
}
function _host_fio_list(){
    local host_ip=$1
    if _ping_check ;then 
        if _ssh_check ;then
            tmpfile=$(mktemp -p $tmpfile_dir)
            tmpfile2=$(mktemp -p $tmpfile_dir)
            host_stat=0
            host_name=$(_ssh_send 'echo $HOSTNAME')
            [[ ${#host_name} -gt 18 ]] && host_name="${host_name:0:18}.."
            # get args info
            local blk_keywd="filename"
            if _ssh_send "ps aux |grep fio |grep rbdname  |grep -vq grep" ;then
                local blk_keywd="rbdname"
            fi
            _ssh_send "ps aux|grep fio|grep $blk_keywd |grep -v grep" > $tmpfile
            # get time info
            _ssh_send "ps -aeo user,pid,etimes,args|grep fio|grep $blk_keywd|grep -v grep |awk '{for(i=3;i<4;i=i+1){printf \$i\" \"};printf \"\n\"}'|sort -u"  > $tmpfile2
            no_job=$(wc -l < $tmpfile) 
            job_pattern=$(awk -F "rw=" '{print$2}' $tmpfile |awk '{print$1}'|sort -u |sed ':label;N;s/\n/\ /;t label')
            job_bs=$(awk -F " -bs=" '{print$2}' $tmpfile |awk '{print$1}'|sort -u |sed ':label;N;s/\n/\ /;t label')
            max_runtime=$(awk -F "runtime=" "{print\$2}" $tmpfile|awk "{print\$1}"|sort -u |head -1)
            disk_list=$(awk -F"$blk_keywd=" '{print$2}' $tmpfile|awk '{print$1}'|sed 's/\/dev\///g' |sort -u |sed ':label;N;s/\n/\ /;t label')
            no_disk=$(awk -F"$blk_keywd=" '{print$2}' $tmpfile|awk '{print$1}' |sort -u |wc -l)
            # nojobs running
            [[ -z $job_pattern ]] && job_pattern="none"
            # mixed read and write, no bs
            if [[ -z ${job_bs// /} ]] ;then
               job_bs=$(awk -F " -bssplit=" '{print$2}' $tmpfile |awk '{print$1}'|sort -u |sed ':label;N;s/\n/\ /;t label') 
               if [[ -n ${job_bs// /} ]] ;then
                   job_bs="mixed"
               else
                   job_bs="none"
               fi
            fi
            if [[ -z "$max_runtime" ]] ;then
                max_runtime="0"
                time_left="0"
            else
                # latest start time
                time_gone=$(sort -n $tmpfile2 |grep -v [a-z,A-Z] |head -1 )
                time_left=$(echo $max_runtime $time_gone |awk '{print$1 - $2}')
                # change format to readable.
                time_left=$(_unit_time "$time_left")
                max_runtime=$(_unit_time "$max_runtime")
            fi
            [[ -z "$disk_list" ]] && disk_list="none"
            #output
        else
            host_stat=1
            host_name='ssh inaccessible :('
        fi 
    else
            host_stat=1
            host_name='ip unreachable :('
    fi
        # check done
        if [[ $host_stat -eq 1 ]] ;then
            check_stat=1
            no_job='-' ;max_runtime='-' ;time_left='-' ;job_bs='-' ;job_pattern='-';no_disk='-' ;disk_list='-'
            printf "\e[1;31m%-21s%-16s%-6s%-12s%-12s%-8s%-11s%-9s%-30s\n\e[0m" "$host_name" "$host_ip" "$no_job" "$max_runtime" "$time_left" "$job_bs" "$job_pattern" "$no_disk" "$disk_list"
        else
            printf "%-21s%-16s%-6s%-12s%-12s%-8s%-11s%-9s%-30s\n" "$host_name" "$host_ip" "$no_job" "$max_runtime" "$time_left" "$job_bs" "$job_pattern" "$no_disk" "$disk_list"
        fi
        rm -rf $tmpfile $tmpfile2 
}
function _group_fio_list(){
# list job on a host group
    _yellow "job list:"
    _parse_host_info "$1"
    # |host name | host ip | No. of jobs | max runtime | disk/file in use | bs | rw pattern | disk/file list |
    printf "%-21s%-16s%-6s%-12s%-12s%-8s%-11s%-9s%-30s\n" "host-name" "host-ip" "jobs" "runtime-max" "remain-max" "bs-size" "rw-pattern" "blk/file" "blk/file-list"
    # get and print job info .
    #    check_stat=0
    local host_exec_function="_host_fio_list"
    if [[ $p_exec == "True" ]];then
        #echo $ip_list 
        #echo $ip_list |xargs -n$host_concurrency_max | _host_concurrent_pipe
        _run_in_concurrent_pipe 
    else
        for host_ip in $ip_list ;do
            _host_fio_list $host_ip
        done
    fi
#    [[ $check_stat -eq 1 ]] && _error_interrupt
#    _unquiet "list action done." || echo -e "\tstat: $check_stat"
}
##############################################################################################
function _host_fio_log_harvest(){
    #
    host_ip=$1
            #for host_ip in $ip_list ;do
                #ping check
                if _ping_check ;then
                    if _ssh_check ;then
    #echo "output_dir $output_dir"
    #sleep 30
                        # stop scp from coping "/" from remote, when output dir missing
                        if [[ -n $output_dir ]] && [[ $output_dir != '/' ]] ;then
                            _scp -r -o ConnectTimeout=$ssh_timeout -P $host_port $host_user@$host_ip:$output_dir/* $output_dir/ 
                            _update_check_stat $? $tmpfile_hvst 
                            # wait
                            _ssh_send "rm -rf $output_dir/"
                            _update_check_stat $? $tmpfile_hvst 
                        else
                            _red "output directory err!" && _verbose "jobinfo"
                            _update_check_stat 1 $tmpfile_hvst 
                        fi
                    else
                        _sshfail 
                        _update_check_stat 1 $tmpfile_hvst 
                    fi
                else
                    _pingfail 
                    #_error_interrupt
                    _update_check_stat 1 $tmpfile_hvst
                fi #&
            #done && wait
}
function _group_fio_log_harvest(){
# blk_group_name was set (when lunch a test on cluster.)
# host_group_name was set
    _yellow "harvest log:"
    # check output dir name 
    if [[ -n $output_dir  ]] ;then
        _parse_host_info "$1"
            tmpfile_hvst=$(mktemp -p $tmpfile_dir)
            #echo 0 > $tmpfile_hvst
            local host_exec_function="_host_fio_log_harvest"
            _run_in_concurrent_pipe
        _confirm_check_stat $tmpfile_hvst
        rm -rf $tmpfile_hvst
        _unquiet "$1: log harvest done."
    else
        _red "empty output dir" && _verbose "jobinfo"
    fi
}
#function _fio_scale_watch(){}
function _host_fio_stop(){
    #
    local host_ip=$1
        #for host_ip in $ip_list ;do
            if _ping_check ;then
                if _ssh_check ;then
                    # stop fio process
                    if _ssh_send 'ps aux |grep fio|grep -E "filename|rbdname" |grep -v grep' &>/dev/null ;then
                        if [[ $tolerate == "True"  ]] ;then
                            _ssh_send 'kill $(ps aux |grep fio|grep -E "rbdname|filename" |grep -v grep|awk "{print\$2}")' \
                            && sleep 3 \
                            && _ssh_send 'plist=$(ps aux |grep fio|grep -E "rbdname|filename" |grep -v grep|awk "{print\$2}"); [[ -z $plist ]] || kill -2 $plist ' \
                            && sleep 3 \
                            && _ssh_send 'plist=$(ps aux |grep fio|grep -E "rbdname|filename" |grep -v grep|awk "{print\$2}"); [[ -z $plist ]] || kill -9 $plist ' \
                            && _unquiet " $(_blue "host: $host_ip") fio process are force killed."
                        else
                            _ssh_send 'kill $(ps aux |grep fio|grep -E "rbdname|filename" |grep -v grep|awk "{print\$2}") &>/dev/null' \
                            && _unquiet " $(_blue "host: $host_ip") fio process killed successfully."
                        fi
                    else
                        _unquiet " $(_blue "host: $host_ip") no fio running"
                    fi
                    _update_check_stat 0 $tmpfile_stop
                else
                    _sshfail 
                    _update_check_stat 1 $tmpfile_stop
                fi
            else
                _pingfail 
                _update_check_stat 1 $tmpfile_stop
                #_error_interrupt
                #echo 1 >$tmpfile_stop
            fi #&
        #done && wait
}
function _group_fio_stop(){
# stop all existing fio jobs on host group
# [[ $tolerate == "True" ]]
    _yellow "fio stop:"
    _parse_host_info "$1"
        tmpfile_stop=$(mktemp -p $tmpfile_dir)
        local host_exec_function="_host_fio_stop"
        _run_in_concurrent_pipe 
# if run in backgroud return will always be 0
        #check_stat=$(cat $tmpfile_stop)
        _confirm_check_stat $tmpfile_stop
        rm -rf $tmpfile_stop
    _unquiet "$1: round stop action done."
}
function _host_test_stop(){
    #
    local host_ip=$1
        #for host_ip in $ip_list ;do
            # stop local process
            local host_pid=$(ps aux |grep $(whoami) |grep $host_ip |grep ssh |grep fio |grep -v grep |awk '{print$2}')
            [[ -n $host_pid ]] && kill $host_pid 
            # stop fio on host
            if _ping_check ;then
                if _ssh_check ;then
                    if _ssh_send 'ps aux |grep fio|grep -E "filename|rbdname" |grep -v grep' &>/dev/null ;then
                        _ssh_send 'kill $(ps aux |grep fio|grep -E "filename|rbdname" |grep -v grep|awk "{print\$2}") ' \
                        && _unquiet " $(_blue "host: $host_ip") fio process killed successfully."
                    else
                        _unquiet " $(_blue "host: $host_ip") no fio running"
                    fi
                    _update_check_stat 0 $tmpfile_stop
                else
                    _sshfail 
                    _update_check_stat 1 $tmpfile_stop
                fi
            else
                _pingfail 
                #_error_interrupt
                #echo 1 >$tmpfile_stop
                _update_check_stat 1 $tmpfile_stop
            fi #&
# if run in backgroud return will always be 0
        #done && wait
}
# stop test on a group
function _group_test_stop(){
    _yellow "test stop:"
    _parse_host_info "$1"
# stop all background test process on local host
    echo "  stop main test process..."
    local main_pid=$(ps aux |grep '\-\-'fio'\ ' |grep "$1" |grep -v grep |awk '{print$2}')
    [[ -n $main_pid ]] && kill $main_pid || echo "  main process was ended already."
#stop fio jobs
        echo "  stop fio jobs on hosts..."
        tmpfile_stop=$(mktemp -p $tmpfile_dir)
        #echo 0 >$tmpfile_stop
        local host_exec_function="_host_fio_stop"
        _run_in_concurrent_pipe 
        #check_stat=$(cat $tmpfile_stop)
        _confirm_check_stat $tmpfile_stop
        rm -rf $tmpfile_stop
    _unquiet "$1: stop action done."
}
function _host_fio_check2(){
    #
    local host_ip=$1
        #for host_ip in $ip_list ;do
        #    _verbose hostinfo && _waiting 5 "reading" 
            if _ping_check ;then
            # no fio between 15 secends check, three times of send interval
                if _ssh_check ;then
                    if _ssh_send 'ps aux |grep fio |grep filename |grep -qv grep ' ;then
                        while _ssh_send 'ps aux |grep fio |grep filename |grep -qv grep ' ;do
                            sleep 30
                        done
                    # rbd test check
                    elif _ssh_send 'ps aux |grep fio |grep rbdname |grep -qv grep ' ;then
                        while _ssh_send 'ps aux |grep fio |grep rbdname |grep -qv grep ' ;do
                            sleep 30
                        done
                    else
                        sleep 15
                        while _ssh_send 'ps aux |grep fio |grep filename |grep -qv grep ' ;do
                            sleep 30
                        done
                        # wait rbd
                        while _ssh_send 'ps aux |grep fio |grep rbdname |grep -qv grep ' ;do
                            sleep 30
                        done
                    fi
                else
                    _sshfail &>/dev/null
                fi
            else
                _pingfail  &>/dev/null
                #_error_interrupt
            fi #&
        #done && wait
}
function _group_fio_check(){
# check and wait when fio jobs detected on a given host group
    _yellow "running stat check:"
    _parse_host_info "$1"
        #check_stat=0
       echo " check and wait running fio jobs."
       local host_exec_function="_host_fio_check2"
       _run_in_concurrent_pipe
    #[[ $check_stat -eq 1 ]] && _error_interrupt
    _unquiet "$1: check action done."  # || echo " group stat : $check_stat" 
}
#function _get_host_yum_pkg_version(){
#    # print software main version 
#    # print int or empty str 
#    local pkg_name=$1
#    local pkg_version=$(_ssh_send "yum list $pkg_name |grep $pkg_name |tail -1 " | awk '{print substr($2, 1, 1)}')
#    if [[ -z ${pkg_version//[0-9]/} ]];then
#        echo "$pkg_version"
#    else
#        return 1
#    fi
#}
#function _get_host_rpm_pkg_version(){
#    # print software main version 
#    local pkg_name=$1
#    local pkg_version=$(_ssh_send "rpm -q $pkg_name" |awk -F[-.] '{print$2}')
#    if [[ -z ${pkg_version//[0-9]/} ]];then
#        echo "$pkg_version"
#    else
#        return 1
#    fi
#}
function _host_pre_check(){
    #
    local host_ip=$1
        #for host_ip in $ip_list ;do
            _verbose "hostinfo" && _waiting 5 "reading" 
            # network check
            if _ping_check ;then
                if ! _ssh_check ;then
                    _sshfail 
                    _update_check_stat 1 $tmpfile_precheck
                    return 1 
                fi
                #check fio installation
                if _ssh_send 'fio -v' &>/dev/null ;then
                    _update_check_stat 0  $tmpfile_precheck
                    # rpm check
                    version=$(_ssh_send "rpm -q fio" |awk -F[-.] '{print$2}')
                    #local version=$(_get_host_rpm_pkg_version "fio")
                    if [[ -z $version ]] ;then
                        _verbose && _blue "host:$host_ip fio was not installed through rpm/yum."
                        # direct check
                        version=$(_ssh_send "fio -v " |awk -F[-.] '{print$2}')
                    fi
                    if [[ $version -ge 3 ]]  ;then
                        _verbose  &&  echo "  host:$host_ip fio check ok"
                    else
                        _unquiet "$(_yellow "warning"): host:$host_ip fio version: $version, version 3+ will be better."
                    fi
                    _update_check_stat 0 $tmpfile_precheck
                # no fio installed
                else
                    # if yum available, check version makecache fast 
                    if _ssh_send 'yum makecache fast >/dev/null' ;then
                        # check version 
                        version=$(_ssh_send "yum list fio|grep fio|tail -1" |awk '{print substr($2, 1, 1)}')
                        #version=$(_get_host_yum_pkg_version "fio")
                        if [[ $version -ge 3 ]] ;then 
                            # fio installing in background 
                            _blue "host:$host_ip, fio installing.."
                            # install fio , makecache 
                            if _ssh_send 'fio -v 2>/dev/null || yum makecache >/dev/null' ;then 
                                _ssh_send 'fio -v 2>/dev/null || yum -y install librbd1 fio &>/dev/null &'
                                # get smartmontools installed
                                _verbose && _ssh_send 'smartctl -V &>/dev/null || yum -y install smartmontools libaio-devel &>/dev/null' & 
                                _update_check_stat 2 $tmpfile_precheck
                            else
                                _red "host:$host_ip: fio installation, makecache failed"
                                _update_check_stat 1 $tmpfile_precheck
                            fi
                        else 
                            echo "host:$host_ip, fio check failed. (not installed and fio version: $version in available repo is lower than 3)"
                            _update_check_stat 1 $tmpfile_precheck
                        fi
                    # yum not available 
                    else
                        _red "host:$host_ip: fio installation, makecache failed"
                        _update_check_stat 1 $tmpfile_precheck
                    fi
                fi
                # try get rsync installed if possible
                #_ssh_send 'rsync --version || yum -y install rsync' &>/dev/null &
            else
                _pingfail 
                #_error_interrupt
                _update_check_stat 1 $tmpfile_precheck
            fi #&
        #done && wait
}
function _group_pre_check(){
# check and wait when fio jobs detected on a given host group
    _yellow "host pre check:"
    _parse_host_info "$1"
#        check_stat=0
        tmpfile_precheck=$(mktemp -p $tmpfile_dir)
        # echo 0 > $tmpfile_precheck
        local host_exec_function="_host_pre_check"
        _run_in_concurrent_pipe
        # check stat
        _confirm_check_stat $tmpfile_precheck
        # install fio, if possible
        if grep -q 2 $tmpfile_precheck ;then 
            # if recheck , count number abort at 3
            if [[ -n $recheck ]] ;then 
                # stop recheck after 3 round recheck
                if [[ $recheck -eq 3 ]] ;then 
                    if grep -q 0 $tmpfile_precheck ;then 
                        _red "host group \"$1\" fio installation failed after $recheck round recheck!!"
                        # skip this group and continue 
                        _error_interrupt
                        return 1
                    else
                        _red "ERROR: NO success signal of fio installation recived on \"$1\" ! it is not possible to continue on this group !!"
                        _red "$date check action abort!"
                        exit 1
                    fi
                else
                    recheck=$[recheck +1] 
                    _yellow "host group $1, fio installation recheck Round_No: $recheck "
                fi
            else
                # first round 
                local recheck=2
                _yellow "check status abnormal, start fio installation recheck ..."
            fi
            # clean tmpfile and recheck 
            rm -rf $tmpfile_precheck
            _yellow "waiting fio installation (yum) ... "
            sleep 20
            _group_pre_check "$1"
        fi
        [[ -f $tmpfile_precheck ]] && rm -rf $tmpfile_precheck &>/dev/null 
        # if fio failed, no need to continue
        #[[ $check_stat -eq 1 ]] && echo "$1 pre check partially failed." && _timeout 15 && _error_interrupt
    _unquiet "host group $1: pre check action done."
}
function _host_blk_detect(){
    #
    local host_ip=$1
        #for host_ip in $ip_list ;do
            #_verbose "hostinfo" && _waiting 5 "reading"
            # network check
            if _ping_check ;then
                # ssh check 
                if  _ssh_check ;then
                    tmpfile_host_blk_detected=$(mktemp -p $tmpfile_dir)
                    # get all blk info form ssh 
                    _ssh_send "lsblk -ps" >$tmpfile_host_blk_detected
                    #check blk device     ## do not quote the slash '', it's not ascii format ! 
                    #local host_blk_detected=$(grep disk $tmpfile_host_blk_detected |grep -v  |awk '{print$1}')
                    local host_blk_detected=$(grep disk $tmpfile_host_blk_detected |grep ^'/' |awk '{print$1}')
                    # get root disk info from root partition
                    local host_root_info=($(grep /$ $tmpfile_host_blk_detected))
                    echo ${host_root_info[@]} |grep -q disk || local host_root_info=($(grep /$ -A1 $tmpfile_host_blk_detected|tail -1))
                    echo ${host_root_info[@]} |grep -q disk || local host_root_info=($(grep /$ -A2 $tmpfile_host_blk_detected|tail -1))
                #echo root info: ${host_root_info[@]}
                    local host_root_disk=${host_root_info[0]//[^a-z,'/']/}
                #echo root name: $host_root_disk
                    # get size info of root disk 
                    local host_root_size=$(grep $host_root_disk'\ ' $tmpfile_host_blk_detected |sort -u |awk '{if(NR==1)print$4}' )
                #echo root size: $host_root_size
                    # check if other data disk same size as root (unparted disk)
                    local RootSize_nu=$(grep ^/ $tmpfile_host_blk_detected |grep $host_root_size|grep disk |wc -l)
#               echo same root size disk number: $RootSize_nu
                    local AllDisk_nu=$(grep ^/ $tmpfile_host_blk_detected |grep disk |wc -l)
                    # check all detected disks on host 
                    for i in $host_blk_detected ;do
                        # add new disk when it's not in detected blk dev list.
                        if ! grep -q $i $tmpfile_grp_blk_detected ;then 
                            # check it's size.
                            local tmp_blk_size=$(grep ^$i'\ ' $tmpfile_host_blk_detected |sort -u |awk '{if(NR==1)print$4}')
                            [[ $tmp_blk_size == $host_root_size ]] && local disk_note=" # same size as disk of root partition"
                            # [[ $? -eq 0 ]] && echo $i size $tmp_blk_size
                            echo $i"," "$disk_note" >> $tmpfile_grp_blk_detected  && disk_note=''
                            #only this (one) unparted blk same size as root, and others not  
                            if [[ $tmp_blk_size == $host_root_size  ]] && [[ $RootSize_nu -eq 1 ]] && [[ $AllDisk_nu -ge $RootSize_nu ]] ;then 
                                sed -i "/^${i//\//\\/}/s/^/#/" $tmpfile_grp_blk_detected
                            fi 
                        fi
                    done
                    rm -f $tmpfile_host_blk_detected
                else 
                    _sshfail 
                fi
            else
                _pingfail 
                #_error_interrupt
            fi #&
        #done && wait 
}
function _group_blk_detect(){
# detected possible target blk on a given host group
    _yellow "group blk detecting:"
    _parse_host_info "$1"
        tmpfile_grp_blk_detected=$(mktemp -p $tmpfile_dir)
        local host_exec_function="_host_blk_detect"
        _run_in_concurrent_pipe 
        #output blk list to group blk configfile 
        echo check done 
        sleep 5
        if [[ ! -f $(dirname $0)/conf/$1".blk" ]] ;then 
            sort -u $tmpfile_grp_blk_detected > $(dirname $0)/conf/$1".blk" 
            sed -i "$ s/\,//g" $(dirname $0)/conf/$1".blk"
            # show detected blk list 
            _yellow "new blk config file: $(dirname $0)/conf/$1.blk"
            cat $(dirname $0)/conf/$1".blk"
        elif ! _format_conf $b_conf |grep -q ^$1 ;then 
            #sed -i "$ s/\,//g" $tmpfile_grp_blk_detected 
            # show detected blk list 
            _yellow "\ncurrently nonpartitioned blk list of group $1:"
            uniq -c $tmpfile_grp_blk_detected
            echo ""
        fi
        # clean tmpfile 
        rm -f $tmpfile_grp_blk_detected
}
function _host_blk_precheck(){
    #
    local host_ip=$1
            #for host_ip in $ip_list;do
                if _ping_check ;then
                    if _ssh_check ;then
                        #
                        for blk in $blk_list ;do 
                            local blk_existence=$(_ssh_send "lsblk -p $blk &>/dev/null && echo 0 || echo 1" )
                            local blk_partition=$(_ssh_send "lsblk -p $blk |grep -v ^NAME |wc -l")
                            # double [[ $(cmd) ]] will stop further expansion.
                            if [[ $blk_existence -ne 0 ]] || [[ $blk_partition -ne 1  ]] ;then
                                _devfail 
                                grep $blk $grp_blk_conf |grep -q '#' && local blk_fail_note=',' || local blk_fail_note='#not found on:'
                                grep $blk $grp_blk_conf |grep -q $host_ip || sed -i "/^${blk//\//\\/}/s/$/$blk_fail_note$host_ip/" $grp_blk_conf
                                #sed -i "/^${blk//\//\\/}/s/^/#/" $grp_blk_conf
                            fi 
                            # unset blk after calling _devfail 
                            unset blk 
                        done
                    else
                        _sshfail 
                    fi
                else
                    _pingfail 
                fi #&
            #done && wait 
}
function _group_blk_precheck(){
    #check if detected blk available on every host 
    _yellow "group blk recheck:"
    _parse_host_info "$1"
    local grp_blk_conf=$(dirname $0)/conf/$1".blk"
    if [[ -f $grp_blk_conf ]] ;then 
        local blk_list=$(_format_conf $grp_blk_conf)
        if [[ -n $blk_list ]] ;then 
            local blk_list=${blk_list//,/ }
            # pipe exec 
            local host_exec_function="_host_blk_precheck"
            _run_in_concurrent_pipe 
            # show blk list after recheck 
            _yellow "currently valid blk list of $1:"
            grep -v "^#" $grp_blk_conf |sed "$ s/\,//g" || _red "  $grp_blk_conf :No valid block device for group: $1 !" 
        else
            _red "  $grp_blk_conf contains no valid block devices."
        fi
    else 
        echo "$grp_blk_conf not exist, skiped"
    fi 
    echo "$1: blk recheck done"
}
function round_report(){
    if [[ -n $job_batch_index ]]; then
        # analise json log
        local   previous_job_group_name="${JOB_BATCH_NAME_ARRAY[$job_batch_index]%%-*}"
        local previous_job_pattern_name="${JOB_BATCH_NAME_ARRAY[$job_batch_index]#*-}"
        # check if multy blkgroup/jobgroup
        local path_flyover=$output_dir 
        [[ $multy_blk_group == "True" ]] && local path_flyover+=/$blk_group_name
        [[ $multy_job_group == "True" ]] && local path_flyover+=/$previous_job_group_name
        # loop through all host, get json file list of last round 
        for host_log_dir  in $(ls $path_flyover/* -d );do 
            # if retest, skip report folder 
            [[ ${host_log_dir##*/} == "_report" ]] && continue 
            for json_file in $(find $host_log_dir -type f -name "$previous_job_pattern_name"*.log.json );do 
                # check format 
                python2 $(dirname $0)/bin/cfiojobs.json.py $json_file &>/dev/null || _red "$json_file : log stat abnormal!"
            done 
        done 
    fi
}
function _list_all_running_jobs(){
    local groups_to_list=$(ps -u $USER -aeo args |grep -E "\-\-fio|\-\-fio\ " |grep -v grep |awk -F'-g' '{print$2}' |awk '{print$1}' |sort -u)
    if [[ -n $groups_to_list ]] ;then
        for i in $groups_to_list ;do
            bash $0 -g $i --fio-list -p 
        done
    else
        echo "no groups to list"
    fi
}
function _test_conflict_check(){
    local pid 
    local conflict_test_list=$(grep "${conflict_args//-/\\-}" $0".hst" |grep -v $$ |awk '{print$2}')
    for pid in $conflict_test_list ;do
        while ps -u $USER -aeo pid,args | grep $pid |grep -q "${conflict_args//-/\\-}"  ;do 
            _warn "TEST ON HOLD, the test you are try to launch is conflicted with an existing test with pid: $pid, args: \"$0 $conflict_args\" on local host."
            sleep 60
        done 
    done
}
function _list_all_hwinfo(){
    local check_opt=$1
    if [[ -n $host_group_list ]] ;then
        for i in $host_group_list ;do
            _yellow "prepare hwinfo tools ..."
            bash $0 -g $i -D $(dirname $0)/tools/hwinfo.run -T /tmp/ &>/dev/null
            bash $0 -g $i "chmod +x /tmp/hwinfo.run; /tmp/hwinfo.run $check_opt ; rm -f /tmp/hwinfo.run " -fp  |sed 1d 
        done
    fi
}
function _get_default_output_dir(){
    if [[ $send_fio == "True"  ]] ;then
        local dir_name="${0#*/}-test-$date"
    else
        local dir_name="${0#*/}-file-$date"
    fi
    echo $dir_name
}
function _check_output_dir(){
    # this functio will be called twice
        #1st check: set variable; check output directory, set default to a datatime stamp.
        local default_output_dir=$(_get_default_output_dir)
        if [[ -z $output_dir ]] ;then
            output_dir="$default_output_dir"
            if [[ ${FUNCNAME[-2]} == "_group_execute" ]] && [[ $send_fio != "True" ]] && [[ -z ${file_group_list// /} ]] ;then 
                return 1
            else
                _info "no output dir name specified, \"$(_yellow "$output_dir")\" will be the default name."
            fi
        #2nd check: hold files.
        elif [[ -d $output_dir ]] || mkdir -p $output_dir ;then
            return 1
        else
            # either 1 or 2 failed.
            if [[ $output_dir == $default_output_dir ]] ;then
                # dir creation failure for default name.
                _warn "the output dir creation failed !" 
            else
                # creation failure for specified name.
                _info "now use \"$output_dir\" as the new output directory, is this ok?"
            fi
            _timeout "15"
        fi
}
function _round_stat(){
    local round_stat=$1
    #
    [[ $group_mode == "single" ]] && local g_stat=", GROUP ROUND: $grp_round/$gtotal"
    _yellow "\n$(date "+%Y-%m-%d_%H:%M:%S"): BLK ROUND $bround/$btotal$g_stat, JOB ROUND $job_batch_index/$total_round $round_stat ..."
}
function _execute_job_batch(){
    #local current_host_group=$1
    # $1 host_group_name 
            #send job batchs to host groups
            for job_batch_index in $(seq 1 $total_round) ;do
                # count number and give process info 
                job_batch=${JOB_BATCH_ARRAY[$job_batch_index]}
                # command_mode check 
                [[ $job_batch_index -ge 2 ]] && [[ $command_mode != "always" ]] && CMD=""

                _recover_job_batch

                #exec on all groups
                _round_stat "EXECUTING"
                #print debug 
                _verbose "roundinfo" && _waiting 5 "reading" 
                if [[ -z $1 ]] && [[ $group_mode == "parallel" ]];then 
                    for host_group_name in $host_group_list ;do
                        _tmp_quiet "on"
                        # wait 10 sec for bknd script status switching
                        sleep 5
                        _record_bknd $host_group_name 
                        _tmp_quiet "off"
                        _group_execute $host_group_name 
                    done && wait && _blue "round $job_batch_index all jobs distributed."
                else
                    _tmp_quiet "on"
                    # wait 10 sec for bknd script status switching
                    sleep 5
                    _record_bknd $1
                    _tmp_quiet "off"
                    _group_execute $1
                    _blue "round $job_batch_index all jobs distributed."
                fi 

                # check jobs 
                _round_stat "CHECKING"
                _tmp_quiet "on"
                # sing group mode 
                if [[ -z $1 ]] && [[ $group_mode == "parallel" ]];then 
                    for host_group_name in $host_group_list ;do
                        _group_fio_check $host_group_name 
                        _group_fio_log_harvest $host_group_name 
                    done && wait
                    _blue "###############| Round $job_batch_index ended |################\n"
                else
                    _group_fio_check $1
                    _group_fio_log_harvest $1
                    _blue "###############| Round $job_batch_index ended |################\n"
                fi 
                _tmp_quiet "off"

                # check fio log stat  
                round_report
            done
            #fio jobs distribution done
            # collect logs 
            echo "waiting log collection ..."
            _tmp_quiet "on"
            # scp in background, log harvest in background, check again here
            while ps aux |grep scp |grep -q $output_dir ;do
                sleep 15
            done && wait 
            echo -e "log collection done\n"
}
function _fio_group_report(){
        #build final report of test
        _yellow "\n$(date "+%Y-%m-%d_%H:%M:%S") FIO TEST \"$output_dir\", LOG ANALYSING ..."
        #final_report
        for blk_group_name in $blk_group_list ;do
            # multy blk_group 
            path_flyover=$output_dir 
            [[ $multy_blk_group == "True" ]] && path_flyover+=/$blk_group_name 
            # loop through multy jobgroup 
            if [[ $multy_job_group == "True" ]] ;then 
                for job_group_dir in $(ls $path_flyover/* -d) ;do 
                    python2 $(dirname $0)/bin/cfiojobs.log2.py $job_group_dir
                    [[ $? -ne 0 ]] && _red "dir: \"$job_group_dir\" status abnormal!" 
                done
            else
                python2 $(dirname $0)/bin/cfiojobs.log2.py $path_flyover 
                [[ $? -ne 0 ]] && _red "dir: \"$path_flyover\" status abnormal!" 
            fi
        done
}
function _fio_env_check(){
        _yellow "\n$(date) FIO TEST ENV PRECHECK  ..."
        #network check, software check
        #set blk_group_name empty skip some parse job
        blk_group_name=""
        for host_group_name in $host_group_list;do
            # check host env (recheck after fio package installation)
            _group_pre_check $host_group_name
        done
}

function _fio_conflict_check(){
    #
    if [[ $conflict_ok == "True" ]] ;then 
        return 0
    else
            #check previous
            _tmp_quiet "on"
            for host_group_name in $host_group_list ;do
                _group_fio_check $host_group_name
            done
            _tmp_quiet "off"
    fi
}
function _fio_scale_control(){
            if [[ $group_mode == "single" ]];then 
                grp_round=0
                gtotal=$(echo $host_group_list|wc -w)
                for host_group_name in $host_group_list;do
                    grp_round=$[grp_round +1]
                    [[ $rbd_mode == "True" ]] && _rbd_expansion $host_group_name 
                    _execute_job_batch $host_group_name 
                done
            else
                [[ $rbd_mode == "True" ]] && _rbd_expansion 
                #echo "${HOST_GROUP_RBD_DEV_ARRAY[ceph2]}"
                _execute_job_batch 
            fi
}


##############################################################################################
# default blobal options
##############################################################################################
#default options set
function _parameter_set(){

pdebug="False"
conf_check="False"
quiet_mode="False"
list_fio="False"
stop_fio="False"
stop_test="False"
send_fio="False"
host_group_list=""
blk_group_list=""
job_group_list=""
execute_mode="normal"
output_dir=""
test_mode="parallel"
group_mode="parallel"
file_group_list=""
file_group_destination=""
tolerate="False"
p_exec="False"
file_group_list=""
harvest_file_group_list=""
multy_job_group="False"
multy_blk_group="False"
recover_test="False"
recover_blk_group_name=""
recover_job_batch_index=""
command_mode="onece"
rbd_mode="False"
ssd_cpid="False"
strict_concurrent_controle="True" 
conflict_ok="False"
no_ping="False"
cmd_prefix=""

}

function _show_info(){
# print all the user options as a rough debug tool
    if [[ $pdebug == "True" ]] ;then
    _yellow " variable stat "
    _blue "\
##################################
function :${FUNCNAME[@]}
info:
      ssd_cpid: $ssd_cpid 
    conf_check: $conf_check
    quiet_mode: $quiet_mode
      list_fio: $list_fio
      stop_fio: $stop_fio
      send_fio: $send_fio
      blk_list: $blk_group_list
      job_list: $job_group_list
     file list: $file_group_list
 harvest_files: $harvest_file_group_list
   destination: $file_group_destination
  execute_mode: $execute_mode
       g group: $host_group_list
       X group: $x_group_list
        x host: $x_host_list
           CMD: $CMD
  command_mode: $command_mode 
    output_dir: $output_dir
  recover_test: $recover_test 
     test_mode: $test_mode
      rbd_mode: $rbd_mode
    group_mode: $group_mode 
    printdebug: $pdebug
      tolerate: $tolerate
     stop_test: $stop_test
        strict: $strict_concurrent_controle 
       no_ping: $no_ping
      sudo_all: $sudo_all
##################################"
    #no_sys_blk: $no_sys_blk
_waiting 10 "read info"
    [[ -z $host_group_list ]] && _red group empty
                [[ -z $CMD ]] && _red cmd empty
           [[ -z $send_fio ]] && _red send_fio empty
     [[ -z $blk_group_list ]] && _red blk list empty
     [[ -z $job_group_list ]] && _red job list empty
    sleep 2
    fi
}

#############################################################################################
# parameters parse and check, get test arguments info  and command 
#############################################################################################
#options check 
[[ -z $1 ]] &&  _show_help_info && exit 0
_parameter_set
# only individual arguments 
_parse_short_args(){
    #
    while [[ $# -gt 0 ]] ;do
        case "$1" in
            #
        "-v" )
            echo "$0 $script_version"
            exit 0
            ;;
        "-h" )
            _show_help_info
            exit 0
            ;;
        "-e" )
            _make_conf_example
            exit 0
            ;;
        "-l" )
            _list_all_running_jobs
            exit 0
            ;;
        "-L" )
            _show_group_info
            exit 0
            ;;
        "-a" )
            _get_all_host_group
            ;;
        "-t" )
            conf_check="True"
            ;;
        "-c" )
            pre_check="True"
            ;;
        "-q" )
            quiet_mode="True"
            ;;
        "-d" )
            pdebug="True"
            ;;
        "-f" )
            tolerate="True"
            ;;
        "-p" )
            p_exec="True"
            ;;
        "-s" )
            test_mode="single"
            ;;
        "-S" )
            group_mode="single"
            ;;
        "-r" )
            rbd_mode="True"
            ;;
        "-A" )
            execute_mode="After"
            ;;
        "-E" )
            command_mode="always"
            ;;
        * )
            _error "wrong format for option \"$1\", please check \"$@\" again!"
            echo "Use \"$0 -h\" to get more help."
            exit 1
            ;;
        esac
        shift 
    done 
}

function _sep_and_parse(){
#    echo "parse: $@"
    while [[ $# -gt 0 ]] ;do
        local alphabet=''
        local args_set=''
        case "$1" in
            "--"* )
                _error "unknown option \"$1\", please check again!"
                echo "Use \"$0 -h\" to get more help."
                exit 1
                ;;
            "-"* )
                # start with a '-'
                # one letter
                alphabet=${1#*-}
                # one charctor
                if [[ ${#alphabet} -eq 1 ]]
                then 
                    args_set+=' '$1
                    shift 
                    continue
                fi 
                # long combinations of letters 
                # echo all short args : ${#alphabet}
                for i in $(seq 0 $((${#alphabet} -1)) )
                do 
                    #echo $i -${alphabet:$i:1}
                    args_set+=' -'${alphabet:$i:1}
                    #echo reparse ${alphabet:$i:1}
                done
                ;;
            * )
                # not start with a '-'
                _error "format error: $1 is not an argument!"
                exit 1
                ;;
        esac
        shift
    done
    # do not quote the args set .
    _parse_short_args $args_set
}

#check option calculating result
while [ $# -gt 0 ] ;do
    case "$1" in
        "-w" )
            if [ $# -lt 2 ]
            then
                echo "$0: -w requires a hostname or host list. multi names separated by comma."
                exit 1
            fi
            host_group_list+=" tmp_specified_host"
            HOST_GROUP_IP_LIST_ARRAY[tmp_specified_host]+=" ${2//,/ }"
            HOST_GROUP_PORT_ARRAY[tmp_specified_host]="${HOST_GROUP_PORT_ARRAY[tmp_specified_host]:-"22"}"
            HOST_GROUP_USER_ARRAY[tmp_specified_host]="${HOST_GROUP_USER_ARRAY[tmp_specified_host]:-"root"}"
            # another shift 
            shift
            ;;
        "-P" )
            if [ $# -lt 2 ]
            then
                echo "$0: -P requires a ssh port number."
                exit 1
            elif ! _check_port "$2"
            then
                echo "wrong format of ssh port \"$2\""
                exit 1
            fi
            HOST_GROUP_PORT_ARRAY[tmp_specified_host]="${2}"
            shift
            ;;
        "-U" )
            if [ $# -lt 2 ]
            then
                echo "$0: -U requires a username."
                exit 1
            fi
            HOST_GROUP_USER_ARRAY[tmp_specified_host]="${2}"
            shift
            ;;
        "-g" )
            if [ $# -lt 2 ]
            then
                echo "$0: -g requires a groupname or group list. multi names separated by comma."
                exit 1
            fi
            host_group_list+=" ${2//,/ }"
            shift
            ;;
        "-x" )
            if [ $# -lt 2 ]
            then
                echo "$0: -x requires a hostname or host/ip list. multi names separated by comma."
                exit 1
            fi
            x_host_list+=" ${2//,/ }"
            shift
            ;;
        "-X" )
            if [ $# -lt 2 ]
            then
                echo "$0: -X requires a groupname or group list.  multi names separated by comma."
                exit 1
            fi
            #there will be a uniq element check, so redundant delimiter is fine here
            x_group_list+=" ${2//,/ }"
            shift
            ;;
        "--fio-list" )
            list_fio="True"
            ;;
        "--fio-stop" )
            stop_fio="True"
            ;;
        "--test-stop" )
            stop_test="True"
            ;;
        "--fio" )
            send_fio="True"
            ;;
        "--cpid" )
            ssd_cpid="True"
            ;;
        "--recover" )
            recover_test="True"
            ;;
        "--recover-from" )
            if [ $# -lt 2 ]
            then
                echo "$0: --recover-from requires a Round Number at least"
                exit 1
            fi
            recover_test="True"
            [[ ${2//,/} != ${2} ]] && recover_blk_group_name=${2%,*}
            recover_job_batch_index=${2##*,}
            shift
            ;;
        "--round-list" )
            round_list="True"
            ;;
        "--round-retest" )
            if [ $# -lt 2 ]
            then
                echo "$0: --round-retest requires a Round Number at least"
                exit 1
            fi
            round_retest="True"
            [[ ${2//,/} != ${2} ]] && recover_blk_group_name=${2%,*}
            recover_job_batch_index=${2##*,}
            shift
            ;;
        "-b" )
            if [ $# -lt 2 ]
            then
                echo "$0: -b requires a blk/file group name or a list of that.  multi names separated by comma."
                exit 1
            fi
            blk_group_list+=" ${2//,/ }"
            shift
            ;;
        "-j" )
            if [ $# -lt 2 ]
            then
                echo "$0: -j requires a job group name or a job group list.  multi names separated by comma."
                exit 1
            fi
            job_group_list+=" ${2//,/ }"
            shift
            ;;
        "-o" )
            if [ $# -lt 2 ]
            then
                echo "$0: -o requires an output directory to work."
                exit 1
            fi
            #remove the last "/"
            if [[ ${2:0-1:1} == / ]] 
            then
                output_dir="${2%/*}"
            else
                output_dir="$2"
            fi
            shift
            ;;
        "-D" )
            if [ $# -lt 2 ]
            then
                echo "$0: -D requires a file list.  multi names separated by comma."
                exit 1
            fi
            file_group_list+=" ${2//,/ }"
            shift
            ;;
        "-C" )
            if [ $# -lt 2 ]
            then
                echo "$0: -C requires a file list.  multi names separated by comma."
                exit 1
            fi
            harvest_file_group_list+="${2}"
            shift
            ;;
        "-T" )
            if [ $# -lt 2 ]
            then
                echo "$0: -T requires an output directory to work."
                exit 1
            fi
            #remove the last "/"
            if [[ ${2:0-1:1} == / ]] 
            then
                file_group_destination="${2%/*}"
            else
                file_group_destination="$2"
            fi
            shift
            ;;
        "--script" )
            if [ $# -lt 2 ]
            then
                echo "$0: --script requires a script file list.  multi names separated by comma."
                exit 1
            fi
            script_file_list_list+=" ${2}"
            shift
            ;;
        "--argument" )
            if [ $# -lt 2 ]
            then
                echo "$0: --argument requires a arg list.  multi args should be double quoted."
                exit 1
            fi
            script_argument_list+=" ${2}"
            shift
            ;;
        "--strictly" )
            if [ $# -lt 2 ] || [ $2 != "False" -a $2 != "True" ]
            then
                echo "$0: --strictly requires a arg of \"True\" or \"False\" ."
                exit 1
            fi
            strict_concurrent_controle="${2}"
            shift
            ;;
        "--conflict-ok" )
            conflict_ok="True"
            ;;
        "--no-ping" )
            no_ping="True"
            ;;
        "--sudo" )
            cmd_prefix="sudo "
            ;;
        "--hwinfo" )
            if [[ $# -lt 2 ]]
            then
                echo "$0: --hwinfo requires a arg word, it should be one of : cpu, mem, nic, hdd, nvme, raid, all. "
                exit 1
            fi
            i=" cpu mem nic hdd nvme raid all "
            j=${2// /}
            [[ ${i//\ $j\ /} == "$i" ]] && _red "unknown option: $2" && exit 1
            if [[ $j == "all" ]];then
                _list_all_hwinfo
            else
                _list_all_hwinfo $2
            fi
            exit 0
            ;;
        "--version" )
            echo "$0 $script_version"
            exit 0
            ;;
        "--help" )
            _show_help_info
            exit 0
            ;;
        * )
            # one word or start with '-'
            if [[ $(echo $1|wc -w) -gt 1 ]] || [[ ${1:0:1} != '-'  ]] ;then 
                #cmd none empty test is needed
                [[ -z $CMD ]] && CMD="$1" || CMD+=" $1"
            else  
                _sep_and_parse "$1"
            fi 
            ;;
    esac
    shift
done


#############################################################################################
# configure file and input options check
#############################################################################################
# after this stage:
# 1. host/blk/job groups are checked.
# 2. usefull inof stored in array.
#running options check
    _show_info
    if [[ $conf_check == "True" ]] ;then 
        _grp_conf_check || exit 1
        _blk_conf_check
        _job_conf_check
    fi
# check blk group, exit with any wrong name, '-d' skip missing group
        _host_group_check
        [[ $strict_concurrent_controle == "True" ]] && _init_concurrency_env $host_concurrency_max 
        #preparation before send fio jobs
        if [[ $send_fio == "True" ]] ;then
            _blk_group_check
            _job_group_check
            _recover_point_check
        else
            #stop job expansion
            blk_stat=2
            job_stat=2
        fi
# confirm blk_stat/grp_stat/job_stat, 0:ok, 1:part failed, 2:all failed.
        if [[ $blk_stat -lt 2 ]] && \
           [[ $job_stat -lt 2 ]] && \
           [[ $grp_stat -lt 2 ]] 
        then
            #job preparation
            _fio_job_expansion
        fi

#############################################################################################
# execute command or start fio test on specified host/blk/job groups
#############################################################################################
# some actions don't need a blk group target.
    # stop fio, list fio, run cmd 
# actions acquire a blk target.
    # send fio


# initialize ssh access 
    if [[ $ssd_cpid == "True" ]] ;then
        read -s -p "Please input host ssh password:" ssh_passwd
        echo "start ssh initializing ..."
        for host_group_name in $host_group_list ;do
            _group_ssd_cpid $host_group_name 
        done
        unset ssh_passwd 
# stop jobs of job round running.
    elif [[ $pre_check == "True" ]] ;then
        echo "start env precheck ..."
        for host_group_name in $host_group_list ;do
            _group_pre_check $host_group_name
            _group_blk_detect $host_group_name
            _group_blk_precheck $host_group_name 
        done
# stop jobs of job round running.
    elif [[ $stop_fio == "True" ]] ;then
        echo "stop fio jobs ..."
        for host_group_name in $host_group_list ;do
            _group_fio_stop $host_group_name
        done
# stop test.
    elif [[ $stop_test == "True" ]] ;then
        echo "stop fio test ..."
        for host_group_name in $host_group_list ;do
            _group_test_stop $host_group_name
        done
# list jobs
    elif [[ $list_fio == "True" ]] ;then
        #
        for host_group_name in $host_group_list ;do
            _group_fio_list $host_group_name
        done
# send files, jobs and cmd
    elif [[ $send_fio == "True" ]] ;then

        _test_conflict_check 
        #check output directory, set default to a datatime stamp.
        _check_output_dir 
        #check test env for all host groups, fio installation, network reachability, ssh access.
        _fio_env_check 
        #mkdir if env check ok.
        _check_output_dir
 
        #send jobs with available blk group
        broud=0
        btotal=$(echo $blk_group_list |wc -w)
        for blk_group_name in $blk_group_list ;do
            bround=$[bround+1]

            # blk group ( round one) info befor start job batch 
            _yellow "\n$(date "+%Y-%m-%d_%H:%M:%S") FIO TEST BLK GROUP: $blk_group_name, PREPARING ..."
            #
            echo -e  "block device group: $(_yellow "$blk_group_name")" 
            _unquiet "dev list : ${BLK_DEV_ARRAY[$blk_group_name]}\n" || echo ""

            _recover_blk_group

            _fio_conflict_check 
            # control the scale by set the test group mode (parallel/single) before start test on host groups 
            _fio_scale_control 

        done
        #blk group

        # cleanning recover log when test is done 
        rm -f $output_dir/recover.log  
        _fio_group_report 

        # end info
        _yellow "\n$(date "+%Y-%m-%d_%H:%M:%S") FIO TEST FINISHED."

# send files and cmd
    elif [[ -n $CMD ]] || [[ -n $file_group_list ]] || [[ -n $harvest_file_group_list ]] ;then
        # check output dir 
        [[ -n $harvest_file_group_list  ]] &&  _check_output_dir 
        # run on group 
        for host_group_name in $host_group_list ;do
            # info 
            [[ -n $CMD ]] && _yellow "command: \"${cmd_prefix}$CMD\"\n"
            [[ -n $file_group_list ]] && _yellow "  send files: \"$file_group_list\""
            [[ -n $harvest_file_group_list ]] && _yellow "  harvest files: \"$harvest_file_group_list\""
            # execute 
            _group_execute $host_group_name
        done
        # cleanning 
    elif [[ -n ${script_file_list_list// /} ]] ;then
        #
        for host_group_name in $host_group_list ;do
            _yellow "script: $script_file_list_list"
            [[ -n $script_argument_list ]] && _yellow "argument: $script_argument_list"
            for script_file_name in $script_file_list_list;do
                _group_ssh_script $host_group_name $script_file_name "$script_argument_list" 
            done
        done
    else 
        _yellow "imcomplete agrs recived, nothing to do."
    fi
    _clean_up

#############################################################################################
# how the blk/job/host groups works in this script.
#############################################################################################
# 1. blk_group_name(str)/job_batch(int) will be checked first in the main script,
#    most functions need all blk/job/host info when they were called.
#    fio related functions called by host_group_name,
#    all host group info were stored in a series array like: HOST_GROUP_XXX_ARRAY[host_group_name].
#
# 2. after job batch expansion, all job group info will be contained in a index ARRAY: JOB_BATCH_ARRAY[index]
#
# 3. job_group_name can be regained from JOB_BATCH_NAME_ARRAY[index].
#
# 4. how these info were ognaized
#    blk_group_list   --> each one blk_group_name               --> its blk_list
#    job_group_list   --> each one job_group_name :bs*pattern   --> its job args assemblage
#    host_group_list  --> each one host_group_name              --> its ip_list
#
# 5. how the process sequnce was set.
#       --> blk group(device scale) 
#       --> job batch(bs*pattern*args) --> single job command (test pattern and mode control)
#                                      --> host group (user,port,ip_list;backend server info)  --> single host (run the test)
#    A host in host group will recive :
#      1). file list (-F xxx,xxx -D xxx)
#      2). device list: fio job arguments list (bs + pattern + other arg set of a job group)
#      3). a command list, and these commands will be executed along with the fio jobs.
#############################################################################################
